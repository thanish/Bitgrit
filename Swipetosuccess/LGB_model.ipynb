{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading the input files\")\n",
    "\n",
    "train_prod = pd.read_pickle(\"../data/train_prod_v16.pickle\")\n",
    "test_prod = pd.read_pickle(\"../data/test_prod_v16.pickle\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod['age_difference'] = train_prod['from_age']-train_prod['to_age']\n",
    "test_prod['age_difference'] = test_prod['from_age']-test_prod['to_age']\n",
    "\n",
    "train_prod['to_swipe_by_session_percentage'] = train_prod['to_total_swipe_counts']/ train_prod['to_total_session_count']\n",
    "train_prod['from_swipe_by_session_percentage'] = train_prod['from_total_swipe_counts']/ train_prod['to_total_session_count']\n",
    "\n",
    "test_prod['to_swipe_by_session_percentage'] = test_prod['to_total_swipe_counts']/ test_prod['to_total_session_count']\n",
    "test_prod['from_swipe_by_session_percentage'] = test_prod['from_total_swipe_counts']/ test_prod['to_total_session_count']\n",
    "\n",
    "\n",
    "train_prod['to_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['to_swipe_left_count']\n",
    "train_prod['from_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['from_swipe_left_count']\n",
    "\n",
    "train_prod['to_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['to_swipe_right_count']\n",
    "train_prod['from_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['from_swipe_right_count']\n",
    "\n",
    "train_prod['to_overall_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['to_total_swipe_counts']\n",
    "train_prod['from_overall_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['from_total_swipe_counts']\n",
    "\n",
    "train_prod['to_overall_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['to_total_swipe_counts']\n",
    "train_prod['from_overall_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['from_total_swipe_counts']\n",
    "\n",
    "test_prod['to_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['to_swipe_left_count']\n",
    "test_prod['from_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['from_swipe_left_count']\n",
    "\n",
    "test_prod['to_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['to_swipe_right_count']\n",
    "test_prod['from_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['from_swipe_right_count']\n",
    "\n",
    "test_prod['to_overall_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['to_total_swipe_counts']\n",
    "test_prod['from_overall_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['from_total_swipe_counts']\n",
    "\n",
    "test_prod['to_overall_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['to_total_swipe_counts']\n",
    "test_prod['from_overall_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['from_total_swipe_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filling Null values\")\n",
    "train_prod.fillna(-999, inplace=True)\n",
    "test_prod.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_bottom_importance = [\n",
    "                         'from_purpose_id_12',\n",
    "                         'to_unique_degree_count',\n",
    "                         'from_purpose_id_3',\n",
    "                         'from_unique_school_count',\n",
    "                         'rev_strength_4',\n",
    "                         'to_unique_school_count',\n",
    "                         'rev_strength_7',\n",
    "                         'rev_strength_8',\n",
    "                         'rev_strength_6',\n",
    "                         'rev_strength_5']\n",
    "\n",
    "self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"_self_intro_\")].tolist()\n",
    "\n",
    "to_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"to_self_intro_\")].tolist()\n",
    "from_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"from_self_intro_\")].tolist()\n",
    "\n",
    "purpose_columns = train_prod.columns[train_prod.columns.str.contains(\"_purpose_\")].tolist()\n",
    "rev_strength_columns = train_prod.columns[train_prod.columns.str.contains(\"rev_strength\")].tolist()\n",
    "common_strength_columns = train_prod.columns[train_prod.columns.str.contains(\"common_strength\")].tolist()\n",
    "review_comments = train_prod.columns[train_prod.columns.str.contains(\"_review_comments_\")].tolist()\n",
    "\n",
    "others = ['to_review_comments_count', 'from_review_comments_count', 'to_last_login_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dep = 'score'\n",
    "drop = ['from-to', 'user_purpose_cosine_similarity', 'to_last_swipe_year']  + review_comments + rev_strength_columns + purpose_columns + to_self_intro_columns + from_self_intro_columns + common_strength_columns\n",
    "indep = train_prod.columns.difference([dep]+drop)\n",
    "\n",
    "print(\"Indep length:\",len(indep))\n",
    "print(\"Columns that are dropped:\", drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Split to train and test local\")\n",
    "np.random.seed(100)\n",
    "train_local_X, test_local_X, train_local_Y, test_local_Y = train_test_split(train_prod[indep],\n",
    "                                                                            train_prod[dep], \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            stratify=train_prod[dep])\n",
    "\n",
    "print(train_local_X.shape, train_local_Y.shape, test_local_X.shape, test_local_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval_accuracy(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = preds.reshape(len(np.unique(labels)), -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    acc = accuracy_score(y_pred = preds, y_true = labels)\n",
    "    return 'Accuracy', acc, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#     'device_type':'gpu',\n",
    "    'nthreads':12,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':4,\n",
    "    'metric': 'custom',\n",
    "    'num_leaves': 170,\n",
    "    #'max_depth': 10,\n",
    "    'learning_rate': 0.04,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_model(train_local_X, train_local_Y, test_local_X, test_local_Y, test_prod):\n",
    "    \n",
    "    lgb_train_local = lgb.Dataset(train_local_X, train_local_Y, free_raw_data=False)\n",
    "    lgb_test_local = lgb.Dataset(test_local_X, test_local_Y, reference=lgb_train_local,  free_raw_data=False)\n",
    "\n",
    "    lgb_test_prod = lgb.Dataset(test_prod[indep], reference=lgb_train_local)\n",
    "\n",
    "    num_rounds = 100000\n",
    "    print('Starting training...')\n",
    "    start = datetime.now()\n",
    "\n",
    "    np.random.seed(100)\n",
    "    lgb_model_local = lgb.train(params,\n",
    "                                lgb_train_local,\n",
    "                                num_boost_round=num_rounds ,\n",
    "                                valid_sets=lgb_test_local,\n",
    "                                feval=lgb_eval_accuracy,\n",
    "                                early_stopping_rounds=30)\n",
    "\n",
    "    lgb_model_local.best_iteration\n",
    "    \n",
    "    end = datetime.now()\n",
    "    print(\"\")\n",
    "    print(\"Total training time:\", end - start)\n",
    "\n",
    "    lgb_prod_prediction = lgb_model_local.predict(test_prod[indep])\n",
    "    \n",
    "    return lgb_prod_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "nfolds = 5\n",
    "kf = KFold(n_splits=nfolds, shuffle=True, random_state=100)\n",
    "\n",
    "all_CV_prediction = {}\n",
    "for i, (train_local_index, test_local_index) in enumerate(kf.split(train_prod[indep])):\n",
    "    \n",
    "    train_local_X, train_local_Y = train_prod.loc[train_local_index, indep], train_prod.loc[train_local_index, dep]\n",
    "    test_local_X, test_local_Y = train_prod.loc[test_local_index, indep], train_prod.loc[test_local_index, dep]\n",
    "    \n",
    "    print(\"Current Fold:\", i)\n",
    "    fold_prediction = train_lgbm_model(train_local_X, train_local_Y, test_local_X, test_local_Y, test_prod)\n",
    "    \n",
    "    all_CV_prediction['fold_'+str(i)] = fold_prediction\n",
    "    print(\"#############################\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold cross validation and average the predictions of all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lgb_prod_prediction = lgb_model_prod.predict(test_prod[indep])\n",
    "\n",
    "final_predictions = np.zeros(shape=(test_prod.shape[0], 4))\n",
    "print(final_predictions.shape)\n",
    "\n",
    "for fold in all_CV_prediction:\n",
    "    print(fold)\n",
    "    final_predictions = final_predictions + all_CV_prediction[fold]\n",
    "\n",
    "# Averaging the output from the CV\n",
    "print(\"Averging all the predictions\")\n",
    "final_predictions = final_predictions/len(all_CV_prediction)\n",
    "\n",
    "lgb_prod_prediction = np.argmax(final_predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_submission = pd.DataFrame({\"from-to\": test_prod['from-to'],\n",
    "                               \"score\": lgb_prod_prediction.astype('float')})\n",
    "\n",
    "lgb_submission.to_csv(\"../submissions/lgb_sub_11.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"forming the LightGBM dataset\")\n",
    "lgb_train_local = lgb.Dataset(train_local_X, train_local_Y, free_raw_data=False)\n",
    "lgb_test_local = lgb.Dataset(test_local_X, test_local_Y, reference=lgb_train_local,  free_raw_data=False)\n",
    "\n",
    "lgb_train_prod = lgb.Dataset(train_prod[indep], train_prod[dep])\n",
    "lgb_test_prod = lgb.Dataset(test_prod[indep], reference=lgb_train_prod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rounds = 10000\n",
    "print('Starting training...')\n",
    "start = datetime.now()\n",
    "\n",
    "np.random.seed(100)\n",
    "lgb_cv = lgb.cv(params,\n",
    "                lgb_train_prod,\n",
    "                nfold=5,\n",
    "                num_boost_round=num_rounds ,\n",
    "                #valid_sets=lgb_test_local,\n",
    "                feval=lgb_eval_accuracy,\n",
    "                early_stopping_rounds=20,\n",
    "                verbose_eval=True)\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Total training time:\", end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print(\"Running the hold out valid\")\n",
    "num_rounds = 10000\n",
    "print('Starting training...')\n",
    "start = datetime.now()\n",
    "\n",
    "np.random.seed(100)\n",
    "lgb_model_local = lgb.train(params,\n",
    "                            lgb_train_local,\n",
    "                            num_boost_round=num_rounds ,\n",
    "                            valid_sets=lgb_test_local,\n",
    "                            feval=lgb_eval_accuracy,\n",
    "                            #categorical_feature=['from', 'to'],\n",
    "                            early_stopping_rounds=50)\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Total training time:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_prediction = lgb_model_local.predict(test_local_X)\n",
    "local_prediction = local_prediction.argmax(axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(test_local_Y, local_prediction))\n",
    "print(\"Confusion matrix\")\n",
    "confusion_matrix(test_local_Y, local_prediction, labels=np.unique(train_prod.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_feature_importance = pd.DataFrame({\"features\" : lgb_model_local.feature_name(),\n",
    "                                       \"importance\" : lgb_model_local.feature_importance()}\n",
    "                                     ).sort_values(['importance'], ascending=False).reset_index(drop=True)\n",
    "print(\"Feature importance top 60\")\n",
    "lgb_feature_importance.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prod model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_round = lgb_model_local.best_iteration + int(lgb_model_local.best_iteration*0.4)\n",
    "\n",
    "print(\"Validation rounds:\", lgb_model_local.best_iteration)\n",
    "print(\"Final round is:\", final_round)\n",
    "\n",
    "print('Starting training...')\n",
    "start = datetime.now()\n",
    "\n",
    "np.random.seed(100)\n",
    "lgb_model_prod = lgb.train(params,\n",
    "                            lgb_train_prod,\n",
    "                            num_boost_round=final_round ,\n",
    "                            valid_sets=lgb_test_local,\n",
    "                            feval=lgb_eval_accuracy,\n",
    "#                             early_stopping_rounds=20\n",
    "                          )\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Total training time:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_prod_prediction = lgb_model_prod.predict(test_prod[indep])\n",
    "lgb_prod_prediction = lgb_prod_prediction.argmax(axis=1)\n",
    "lgb_prod_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_submission = pd.DataFrame({\"from-to\": test_prod['from-to'],\n",
    "                               \"score\": lgb_prod_prediction.astype('float')})\n",
    "\n",
    "lgb_submission.to_csv(\"../submissions/lgb_sub_30.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
