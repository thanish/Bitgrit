{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from network import RNN_for_Text, NN_for_num_Features, MulticlassClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'batch_size' : 5096,\n",
    "          'num_worker' : 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903605, 785) (387975, 784)\n"
     ]
    }
   ],
   "source": [
    "train_prod = pd.read_pickle(\"../data/train_prod_v14.pickle\")\n",
    "test_prod = pd.read_pickle(\"../data/test_prod_v14.pickle\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Find the age difference\")\n",
    "\n",
    "train_prod['age_difference'] = train_prod['from_age']-train_prod['to_age']\n",
    "test_prod['age_difference'] = test_prod['from_age']-test_prod['to_age']\n",
    "\n",
    "train_prod['to_swipe_by_session_percentage'] = (train_prod['to_total_swipe_counts']/ train_prod['to_total_session_count']).replace(np.inf, 0)\n",
    "train_prod['from_swipe_by_session_percentage'] = (train_prod['from_total_swipe_counts']/ train_prod['to_total_session_count']).replace(np.inf, 0)\n",
    "\n",
    "test_prod['to_swipe_by_session_percentage'] = (test_prod['to_total_swipe_counts']/ test_prod['to_total_session_count']).replace(np.inf, 0)\n",
    "test_prod['from_swipe_by_session_percentage'] = (test_prod['from_total_swipe_counts']/ test_prod['to_total_session_count']).replace(np.inf, 0)\n",
    "\n",
    "train_prod['to_common_users_left_swipe_percentage'] = (train_prod['common_users_swiped_left']/train_prod['to_swipe_left_count']).replace(np.inf, 0)\n",
    "train_prod['from_common_users_left_swipe_percentage'] = (train_prod['common_users_swiped_left']/train_prod['from_swipe_left_count']).replace(np.inf, 0)\n",
    "\n",
    "train_prod['to_common_users_right_swipe_percentage'] = (train_prod['common_users_swiped_right']/train_prod['to_swipe_right_count']).replace(np.inf, 0)\n",
    "train_prod['from_common_users_right_swipe_percentage'] = (train_prod['common_users_swiped_right']/train_prod['from_swipe_right_count']).replace(np.inf, 0)\n",
    "\n",
    "train_prod['to_overall_common_users_left_swipe_percentage'] = (train_prod['common_users_swiped_left']/train_prod['to_total_swipe_counts']).replace(np.inf, 0)\n",
    "train_prod['from_overall_common_users_left_swipe_percentage'] = (train_prod['common_users_swiped_left']/train_prod['from_total_swipe_counts']).replace(np.inf, 0)\n",
    "\n",
    "train_prod['to_overall_common_users_right_swipe_percentage'] = (train_prod['common_users_swiped_right']/train_prod['to_total_swipe_counts']).replace(np.inf, 0)\n",
    "train_prod['from_overall_common_users_right_swipe_percentage'] = (train_prod['common_users_swiped_right']/train_prod['from_total_swipe_counts']).replace(np.inf, 0)\n",
    "\n",
    "test_prod['to_common_users_left_swipe_percentage'] = (test_prod['common_users_swiped_left']/test_prod['to_swipe_left_count']).replace(np.inf, 0)\n",
    "test_prod['from_common_users_left_swipe_percentage'] = (test_prod['common_users_swiped_left']/test_prod['from_swipe_left_count']).replace(np.inf, 0)\n",
    "\n",
    "test_prod['to_common_users_right_swipe_percentage'] = (test_prod['common_users_swiped_right']/test_prod['to_swipe_right_count']).replace(np.inf, 0)\n",
    "test_prod['from_common_users_right_swipe_percentage'] = (test_prod['common_users_swiped_right']/test_prod['from_swipe_right_count']).replace(np.inf, 0)\n",
    "\n",
    "test_prod['to_overall_common_users_left_swipe_percentage'] = (test_prod['common_users_swiped_left']/test_prod['to_total_swipe_counts']).replace(np.inf, 0)\n",
    "test_prod['from_overall_common_users_left_swipe_percentage'] = (test_prod['common_users_swiped_left']/test_prod['from_total_swipe_counts']).replace(np.inf, 0)\n",
    "\n",
    "test_prod['to_overall_common_users_right_swipe_percentage'] = (test_prod['common_users_swiped_right']/test_prod['to_total_swipe_counts']).replace(np.inf, 0)\n",
    "test_prod['from_overall_common_users_right_swipe_percentage'] = (test_prod['common_users_swiped_right']/test_prod['from_total_swipe_counts']).replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903605, 796) (387975, 795)\n"
     ]
    }
   ],
   "source": [
    "train_prod = train_prod.replace(999999, 0) \n",
    "test_prod = test_prod.replace(999999, 0) \n",
    "train_prod.fillna(0, inplace=True)\n",
    "test_prod.fillna(0, inplace=True)\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 184\n",
      "Text features: 600\n",
      "Total indep features 785\n"
     ]
    }
   ],
   "source": [
    "lgb_bottom_importance = [\n",
    "                         'from_purpose_id_12',\n",
    "                         'to_unique_degree_count',\n",
    "                         'from_purpose_id_3',\n",
    "                         'from_unique_school_count',\n",
    "                         'rev_strength_4',\n",
    "                         'to_unique_school_count',\n",
    "                         'rev_strength_7',\n",
    "                         'rev_strength_8',\n",
    "                         'rev_strength_6',\n",
    "                         'rev_strength_5']\n",
    "\n",
    "to_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"to_self_intro_\")].tolist()\n",
    "from_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"from_self_intro_\")].tolist()\n",
    "review_columns = train_prod.columns[train_prod.columns.str.contains(\"rev_strength\")].tolist()\n",
    "\n",
    "id_feature = ['from-to']\n",
    "dep = ['score']\n",
    "drop = ['user_purpose_cosine_similarity', 'to_last_swipe_year'] + review_columns\n",
    "\n",
    "text_embed_columns = train_prod.columns[train_prod.columns.str.contains(\"_self_intro_\")].tolist()\n",
    "num_feature_columns = train_prod.columns.difference(text_embed_columns + id_feature + dep + drop ).tolist()\n",
    "indep = id_feature + text_embed_columns + num_feature_columns\n",
    "\n",
    "print(f\"Numerical features: {len(num_feature_columns)}\")\n",
    "print(f\"Text features: {len(text_embed_columns)}\")\n",
    "print(f\"Total indep features {len(indep)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_prod[num_feature_columns])\n",
    "\n",
    "train_prod[num_feature_columns] = scaler.transform(train_prod[num_feature_columns])\n",
    "test_prod[num_feature_columns] = scaler.transform(test_prod[num_feature_columns])\n",
    "\n",
    "train_prod.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormInputs():\n",
    "    def __init__(self, features, label, id_feature, num_features, intro_features, datatype='train'):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.id_feature=id_feature\n",
    "        self.num_columns = num_features\n",
    "        self.intro_columns = intro_features\n",
    "        self.datatype=datatype\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        id_feature = self.features.loc[index, self.id_feature]\n",
    "        num_features = self.features.loc[index, self.num_columns]\n",
    "        intro_features = self.features.loc[index, self.intro_columns]\n",
    "        \n",
    "        if self.datatype=='test':\n",
    "            Y = 1\n",
    "        else:\n",
    "            Y = self.label.loc[index, :]\n",
    "            \n",
    "        return {'id_feature':id_feature.values.tolist(), \n",
    "                'num_features': torch.tensor(num_features, dtype=torch.float),\n",
    "                'intro_features': torch.tensor(intro_features, dtype=torch.float),\n",
    "                'target' : torch.tensor(Y, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_input = FormInputs(features=train_prod[indep], label=train_prod[dep],\n",
    "                              id_feature=id_feature,\n",
    "                              num_features=num_feature_columns,\n",
    "                              intro_features=text_embed_columns,\n",
    "                              datatype='train')\n",
    "\n",
    "test_prod_input = FormInputs(features=test_prod[indep], label=None,\n",
    "                             id_feature=id_feature,\n",
    "                             num_features=num_feature_columns,\n",
    "                             intro_features=text_embed_columns,\n",
    "                             datatype='test')\n",
    "\n",
    "train_prod_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_data_loader = torch.utils.data.DataLoader(train_prod_input,\n",
    "                                                     shuffle=True,\n",
    "                                                     batch_size=config['batch_size'],\n",
    "                                                     num_workers=config['num_worker'])\n",
    "test_prod_data_loader = torch.utils.data.DataLoader(test_prod_input,\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size=config['batch_size'],\n",
    "                                                    num_workers=config['num_worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_seed(seed_no):\n",
    "    random.seed(seed_no)\n",
    "    np.random.seed(seed_no)\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed_all(seed_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [08:07<00:00,  2.74s/it]\n",
      "100%|██████████| 77/77 [03:22<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "text_hidden_dim=600\n",
    "text_output_dim=100\n",
    "\n",
    "num_hidden_dim=184\n",
    "num_output_dim=50\n",
    "\n",
    "text_features = len(text_embed_columns)\n",
    "numeric_features = len(num_feature_columns)\n",
    "\n",
    "def get_features(data_loader):\n",
    "    '''\n",
    "    In this function we pass the text features embedding through the RNN network to get the final embeddings.\n",
    "    Numerical features are passed through the dense layer to get the final embeddings.\n",
    "    Both these embedding are concatenated together returned as output.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    RNN_model = RNN_for_Text(embedding_dim=text_features, hidden_dim=text_hidden_dim, output_dim=text_output_dim).to(device)\n",
    "    Num_model = NN_for_num_Features(num_features=numeric_features, hidden_dim=num_hidden_dim, output_dim=num_output_dim).to(device)\n",
    "    \n",
    "    id_col = np.array([])\n",
    "    target_col = np.array([])\n",
    "    text_embed_output = torch.tensor([])\n",
    "    num_embed_output = torch.tensor([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "            id_features = data['id_feature']\n",
    "            num_features = data['num_features'].to(device)\n",
    "            intro_features = data['intro_features'].to(device)\n",
    "            label = data['target'].to(device)\n",
    "            \n",
    "            # Passing to the RNN model\n",
    "            temp_text_embed = RNN_model(intro_features)\n",
    "            temp_text_embed = temp_text_embed.view(-1, text_output_dim)\n",
    "            text_embed_output = torch.cat([text_embed_output, temp_text_embed])\n",
    "\n",
    "            # Passing into a linear Dense NN\n",
    "            temp_num_embed = Num_model(num_features)\n",
    "            num_embed_output = torch.cat([num_embed_output, temp_num_embed])\n",
    "\n",
    "            id_col = np.append(id_col, id_features)\n",
    "            target_col = np.append(target_col, label) \n",
    "            \n",
    "    return id_col, target_col, text_embed_output, num_embed_output\n",
    "\n",
    "train_id_col, train_target_col, train_prod_text_embed_output, train_prod_num_embed_output = get_features(data_loader=train_prod_data_loader)\n",
    "test_id_col, test_target_col, test_prod_text_embed_output, test_prod_num_embed_output = get_features(data_loader=test_prod_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ID features:(903605,)\n",
      "Train target features:(903605,)\n",
      "Train Text features:torch.Size([903605, 100])\n",
      "Train Num features:torch.Size([903605, 50])\n",
      "Train text and num features:torch.Size([903605, 150])\n",
      "\n",
      "Test ID features:(387975,)\n",
      "Test target features:(387975,)\n",
      "Test Text features:torch.Size([387975, 100])\n",
      "Test Num features:torch.Size([387975, 50])\n",
      "Test text and num features:torch.Size([387975, 150])\n"
     ]
    }
   ],
   "source": [
    "train_prod_text_num_concat = torch.cat([train_prod_text_embed_output, train_prod_num_embed_output], axis=1)\n",
    "test_prod_text_num_concat = torch.cat([test_prod_text_embed_output, test_prod_num_embed_output], axis=1)\n",
    "\n",
    "final_features = train_prod_text_num_concat.shape[1]\n",
    "\n",
    "print(f\"Train ID features:{train_id_col.shape}\")\n",
    "print(f\"Train target features:{train_target_col.shape}\")\n",
    "print(f\"Train Text features:{train_prod_text_embed_output.shape}\")\n",
    "print(f\"Train Num features:{train_prod_num_embed_output.shape}\")\n",
    "print(f\"Train text and num features:{train_prod_text_num_concat.shape}\")\n",
    "print(\"\")\n",
    "print(f\"Test ID features:{test_id_col.shape}\")\n",
    "print(f\"Test target features:{test_target_col.shape}\")\n",
    "print(f\"Test Text features:{test_prod_text_embed_output.shape}\")\n",
    "print(f\"Test Num features:{test_prod_num_embed_output.shape}\")\n",
    "print(f\"Test text and num features:{test_prod_text_num_concat.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.concatenate((train_id_col.reshape(-1, 1), train_target_col.reshape(-1, 1), train_prod_text_embed_output, train_prod_num_embed_output), axis=1)\n",
    "test_set = np.concatenate((test_id_col.reshape(-1, 1), test_prod_text_embed_output, test_prod_num_embed_output), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = [\"text_embed_\"+str(i) for i in range(text_output_dim)]\n",
    "num_col = [\"num_embed_\"+str(i) for i in range(num_output_dim)]\n",
    "\n",
    "train_set = pd.DataFrame(train_set)\n",
    "train_set.columns = ['from-to']+['score']+text_col+num_col\n",
    "\n",
    "test_set = pd.DataFrame(test_set)\n",
    "test_set.columns = ['from-to']+text_col+num_col\n",
    "\n",
    "train_set[['score']+text_col+num_col] = train_set[['score']+text_col+num_col].astype('float')\n",
    "test_set[text_col+num_col] = test_set[text_col+num_col].astype('float')\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_embed_0', 'num_embed_1', 'num_embed_10', 'num_embed_11',\n",
       "       'num_embed_12', 'num_embed_13', 'num_embed_14', 'num_embed_15',\n",
       "       'num_embed_16', 'num_embed_17', 'num_embed_18', 'num_embed_19',\n",
       "       'num_embed_2', 'num_embed_20', 'num_embed_21', 'num_embed_22',\n",
       "       'num_embed_23', 'num_embed_24', 'num_embed_25', 'num_embed_26',\n",
       "       'num_embed_27', 'num_embed_28', 'num_embed_29', 'num_embed_3',\n",
       "       'num_embed_30', 'num_embed_31', 'num_embed_32', 'num_embed_33',\n",
       "       'num_embed_34', 'num_embed_35', 'num_embed_36', 'num_embed_37',\n",
       "       'num_embed_38', 'num_embed_39', 'num_embed_4', 'num_embed_40',\n",
       "       'num_embed_41', 'num_embed_42', 'num_embed_43', 'num_embed_44',\n",
       "       'num_embed_45', 'num_embed_46', 'num_embed_47', 'num_embed_48',\n",
       "       'num_embed_49', 'num_embed_5', 'num_embed_6', 'num_embed_7',\n",
       "       'num_embed_8', 'num_embed_9', 'text_embed_0', 'text_embed_1',\n",
       "       'text_embed_10', 'text_embed_11', 'text_embed_12', 'text_embed_13',\n",
       "       'text_embed_14', 'text_embed_15', 'text_embed_16', 'text_embed_17',\n",
       "       'text_embed_18', 'text_embed_19', 'text_embed_2', 'text_embed_3',\n",
       "       'text_embed_4', 'text_embed_5', 'text_embed_6', 'text_embed_7',\n",
       "       'text_embed_8', 'text_embed_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep = 'score'\n",
    "id_feature = ['from-to']\n",
    "indep = train_set.columns.difference(id_feature+[dep])\n",
    "indep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output from the above methods are passed as input to the final Neural network layers in the subsequent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722884, 70) (722884,) (180721, 70) (180721,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_local_X, test_local_X, train_local_Y, test_local_Y = train_test_split(train_set[indep],\n",
    "                                                                            train_set[dep], \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            stratify=train_set[dep])\n",
    "\n",
    "train_local_X, test_local_X, train_local_Y, test_local_Y = train_local_X.reset_index(drop=True), test_local_X.reset_index(drop=True), train_local_Y.reset_index(drop=True), test_local_Y.reset_index(drop=True)\n",
    "\n",
    "print(train_local_X.shape, train_local_Y.shape, test_local_X.shape, test_local_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormInputs_v2():\n",
    "    def __init__(self, features, label, id_feature, datatype='train'):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.id_feature=id_feature\n",
    "        self.datatype=datatype\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = self.features.loc[index, :]\n",
    "        #id_feature = self.features.loc[index, self.id_feature]\n",
    "        \n",
    "        if self.datatype=='test':\n",
    "            Y = 1\n",
    "        else:\n",
    "            Y = self.label[index]\n",
    "            \n",
    "        return {'features':torch.tensor(X, dtype=torch.float), \n",
    "                'target' : torch.tensor(Y, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': tensor([-0.1316, -0.2858, -0.0910, -0.1259, -0.1682, -0.2966, -0.1103,  0.0168,\n",
       "         -0.1502,  0.1775, -0.3764, -0.0737, -0.0307, -0.4879,  0.0754, -0.4804,\n",
       "         -0.3590,  0.1910,  0.0871,  0.2194,  0.0723, -0.1846,  0.2590,  0.3882,\n",
       "         -0.0378,  0.0484, -0.2049, -0.0090, -0.0235, -0.1203, -0.0377,  0.0665,\n",
       "         -0.1807,  0.1256, -0.1030,  0.0661, -0.4802, -0.0856,  0.3613,  0.1793,\n",
       "          0.1104,  0.2613, -0.1044, -0.1081, -0.0211, -0.5167,  0.0357,  0.0074,\n",
       "         -0.1306, -0.3530, -0.2787,  0.0880,  0.0470, -0.3388,  1.0979, -0.3980,\n",
       "          0.5047, -0.2246, -0.6184,  0.1844,  0.3295, -0.5399,  0.9563,  0.6263,\n",
       "         -0.2246, -0.9370, -0.0734, -0.3513,  0.7549, -1.3140]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_local_input = FormInputs_v2(features=train_local_X, label=train_local_Y,\n",
    "                                      id_feature=id_feature,\n",
    "                                      datatype='train')\n",
    "\n",
    "test_set_local_input = FormInputs_v2(features=test_local_X, label=test_local_Y,\n",
    "                                     id_feature=id_feature,\n",
    "                                     datatype='train')\n",
    "\n",
    "train_set_prod_input = FormInputs_v2(features=train_set[indep], label=train_set[dep],\n",
    "                                     id_feature=id_feature,\n",
    "                                     datatype='train')\n",
    "\n",
    "test_set_prod_input = FormInputs_v2(features=test_set[indep], label=None,\n",
    "                                    id_feature=id_feature,\n",
    "                                    datatype='test')\n",
    "\n",
    "train_set_prod_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_local_data_loader = torch.utils.data.DataLoader(train_set_local_input,\n",
    "                                                      shuffle=True,\n",
    "                                                      batch_size=config['batch_size'],\n",
    "                                                      num_workers=config['num_worker'])\n",
    "test_set_local_data_loader = torch.utils.data.DataLoader(test_set_local_input,\n",
    "                                                     shuffle=True,\n",
    "                                                     batch_size=config['batch_size'],\n",
    "                                                     num_workers=config['num_worker'])\n",
    "train_set_prod_data_loader = torch.utils.data.DataLoader(train_set_prod_input,\n",
    "                                                     shuffle=True,\n",
    "                                                     batch_size=config['batch_size'],\n",
    "                                                     num_workers=config['num_worker'])\n",
    "test_set_prod_data_loader = torch.utils.data.DataLoader(test_set_prod_input,\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size=config['batch_size'],\n",
    "                                                    num_workers=config['num_worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, data_loader):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    final_loss = 0\n",
    "    for i, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        feature = data['features'].to(device)\n",
    "        target = data['target'].to(device)\n",
    "        \n",
    "        prediction = model(feature)\n",
    "        \n",
    "        prediction_soft_max = nn.Softmax(dim=1)(prediction)\n",
    "        prediction_soft_max = prediction_soft_max.argmax(axis=1)\n",
    "        #print(\"train_actual:\", np.unique(target.detach().cpu().numpy(), return_counts=True))\n",
    "        #print(\"train_predicted:\", np.unique(prediction_soft_max.detach().cpu().numpy(), return_counts=True))\n",
    "        \n",
    "        loss = loss_func(prediction, target)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        final_loss += loss\n",
    "    \n",
    "    final_loss = final_loss/len(data_loader)\n",
    "    \n",
    "    return model, final_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, data_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    final_loss = 0\n",
    "    actual_output=[]\n",
    "    predicted_output=[]\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            feature = data['features'].to(device)\n",
    "            target = data['target'].to(device)\n",
    "            \n",
    "            prediction = model(feature)\n",
    "                        \n",
    "            loss = loss_func(prediction, target)\n",
    "            final_loss += loss\n",
    "            \n",
    "            #print(\"validation_prediction:\", prediction)\n",
    "            \n",
    "            prediction = nn.Softmax(dim=1)(prediction)\n",
    "            \n",
    "            #print(\"softmax_prediction:\", prediction)\n",
    "            \n",
    "            prediction = prediction.argmax(axis=1)\n",
    "            \n",
    "            #print(\"Argmax_prediction:\", prediction)\n",
    "            \n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "                        \n",
    "        print(\"Predicted output:\", np.unique(predicted_output, return_counts=True))\n",
    "        print(\"Actual output:\", np.unique(actual_output, return_counts=True))\n",
    "        print(confusion_matrix(y_true=actual_output, y_pred=predicted_output))\n",
    "        \n",
    "        final_loss = final_loss/len(data_loader)\n",
    "        accuracy = accuracy_score(predicted_output, actual_output)\n",
    "    \n",
    "    return final_loss, actual_output, predicted_output, accuracy       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(model, data_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predicted_output=[]\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            feature = data['features'].to(device)\n",
    "            \n",
    "            prediction = model(feature)\n",
    "                        \n",
    "            prediction = nn.Softmax(dim=1)(prediction)\n",
    "            prediction = prediction.argmax(axis=1)\n",
    "            \n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "                        \n",
    "    return predicted_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_engine(epochs, train_data, eval_data, patience):\n",
    "    \n",
    "    setting_seed(seed_no=100)\n",
    "    model = MulticlassClassification(num_features=final_features, num_labels=4)\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "        \n",
    "    counter = 0\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        model, train_loss = train_fn(model, optimizer, data_loader=train_data)\n",
    "        eval_loss, eval_actual, eval_prediction, accuracy = eval_fn(model, data_loader=eval_data)\n",
    "        \n",
    "        print(\"Epoch: {} train loss: {} eval loss: {} eval accuracy {}\".format(epoch, train_loss, eval_loss, accuracy))\n",
    "        \n",
    "        if accuracy > best_accuracy:  \n",
    "        \n",
    "            best_accuracy = accuracy\n",
    "            counter = 0\n",
    "\n",
    "            model_path = '../saved_model/best_model_1.bin'            \n",
    "            print(\"Saving the model:\", model_path)\n",
    "            torch.save(model, model_path)\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "            print(\"Patience:\", counter)\n",
    "            \n",
    "            if counter == patience:\n",
    "                print(\"Reached the patience threshold so ending the training\")\n",
    "                break            \n",
    "        \n",
    "        print(\"Best Accuracy:\", best_accuracy)\n",
    "        \n",
    "    return model, eval_actual, eval_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, eval_actual, eval_prediction = train_engine(epochs = 500, \n",
    "                                                   train_data=train_set_local_data_loader, \n",
    "                                                   eval_data=test_set_local_data_loader,\n",
    "                                                   patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_save_path = '../saved_model/saved_state'\n",
    "loaded_state = torch.load(state_save_path)\n",
    "\n",
    "model = MulticlassClassification(num_features=len(indep), num_labels=4)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "model_weight = model.load_state_dict(loaded_state['model_state_dict'])\n",
    "model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
