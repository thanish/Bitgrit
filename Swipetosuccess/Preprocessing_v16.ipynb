{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading the train and test files\")\n",
    "train_prod = pd.read_csv(\"../data/train.csv\")\n",
    "test_prod = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Reading the interaction files\")\n",
    "interaction_swipe = pd.read_csv('../data/interaction_swipes.csv')\n",
    "interaction_review_strength = pd.read_csv(\"../data/interaction_review_strengths.csv\")\n",
    "interaction_review_comments = pd.read_csv(\"../data/interaction_review_comments_300dims.csv\")\n",
    "\n",
    "print(\"Reading the User files\")\n",
    "user_strengths = pd.read_csv(\"../data/user_strengths.csv\")\n",
    "user_ages = pd.read_csv(\"../data/user_ages.csv\")\n",
    "user_educations = pd.read_csv(\"../data/user_educations.csv\")\n",
    "user_purpose = pd.read_csv(\"../data/user_purposes.csv\")\n",
    "user_self_intro = pd.read_csv(\"../data/user_self_intro_vectors_300dims.csv\")\n",
    "user_sessions = pd.read_csv(\"../data/user_sessions.csv\")\n",
    "user_skills = pd.read_csv(\"../data/user_skills.csv\")\n",
    "user_works = pd.read_csv(\"../data/user_works.csv\")\n",
    "\n",
    "print(\"All files read\")\n",
    "print(\"\")\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading the train and test files\")\n",
    "train_prod = pd.read_csv(\"../data/train.csv\")\n",
    "test_prod = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Reading the interaction files\")\n",
    "interaction_swipe = pd.read_csv('../data/interaction_swipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the from-to in Train and Test prod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting the to and from in the train and test dataset\")\n",
    "\n",
    "train_prod[['from', 'to']] = pd.DataFrame(train_prod['from-to'].str.split(\"-\").tolist(), index= train_prod.index)\n",
    "train_prod = train_prod[['from-to', 'from', 'to', 'score']]\n",
    "\n",
    "test_prod[['from', 'to']] = pd.DataFrame(test_prod['from-to'].str.split(\"-\").tolist(), index= test_prod.index)\n",
    "\n",
    "train_prod['to'] = train_prod['to'].astype('int')\n",
    "train_prod['from'] = train_prod['from'].astype('int')\n",
    "test_prod['to'] = test_prod['to'].astype('int')\n",
    "test_prod['from'] = test_prod['from'].astype('int')\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction swipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Removing the duplicates in the interaction swipe and converting the date to timestamp format\")\n",
    "\n",
    "print(interaction_swipe.shape)\n",
    "interaction_swipe = interaction_swipe[~interaction_swipe.duplicated()]\n",
    "print(interaction_swipe.shape)\n",
    "interaction_swipe['timestamp'] = interaction_swipe.timestamp.astype('str')\n",
    "interaction_swipe['timestamp'] = pd.to_datetime(interaction_swipe.timestamp,  errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the from and to from the from-to \n",
    "print(\"Splitting the to and from in in the interaction swipe dataset\")\n",
    "\n",
    "interaction_swipe[['from', 'to']] = pd.DataFrame(interaction_swipe['from-to'].str.split(\"-\").tolist(), index= interaction_swipe.index)\n",
    "interaction_swipe = interaction_swipe[['from-to', 'from', 'to', 'timestamp', 'swipe_status']]\n",
    "\n",
    "interaction_swipe['to'] = interaction_swipe['to'].astype('int')\n",
    "interaction_swipe['from'] = interaction_swipe['from'].astype('int')\n",
    "interaction_swipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the date features the interaction swipe dataset\")\n",
    "\n",
    "interaction_swipe['hour'] = interaction_swipe.timestamp.dt.hour\n",
    "interaction_swipe['year'] = interaction_swipe.timestamp.dt.year\n",
    "interaction_swipe['month'] = interaction_swipe.timestamp.dt.month\n",
    "interaction_swipe['day'] = interaction_swipe.timestamp.dt.day\n",
    "interaction_swipe['weekday'] = interaction_swipe.timestamp.dt.weekday\n",
    "interaction_swipe['weekends'] = np.where(interaction_swipe.weekday>=5, 1, 0)\n",
    "interaction_swipe.dropna(inplace=True)\n",
    "interaction_swipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the First and last swipe of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def first_last_swipe_year(df, side):\n",
    "    temp = df.groupby([side]).agg(first_swipe_year = ('year', 'min'),\n",
    "                                  last_swipe_year = ('year', 'max')).reset_index()\n",
    "    temp['swipe_year_difference'] = temp.last_swipe_year - temp.first_swipe_year\n",
    "    temp.columns = [side, side+'_first_swipe_year', side+'_last_swipe_year', side+'_swipe_year_difference']\n",
    "    return temp\n",
    "\n",
    "from_first_last_swipe_year = first_last_swipe_year(df=interaction_swipe.copy(), side='from')\n",
    "to_first_last_swipe_year = first_last_swipe_year(df=interaction_swipe.copy(), side='to')\n",
    "\n",
    "from_first_last_swipe_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the total swipe days of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def total_swipe_days(df, side):\n",
    "    temp = df.groupby([side, 'year', 'month', 'day']).agg(unique_days = ('day', 'nunique')).reset_index()\n",
    "    temp = temp.groupby([side]).agg(total_swipe_days = ('unique_days', 'sum')).reset_index()\n",
    "    temp.columns = [side, side+'_total_swipe_days']\n",
    "    return temp\n",
    "\n",
    "from_total_swipe_days = total_swipe_days(df=interaction_swipe.copy(), side='from')\n",
    "to_total_swipe_days = total_swipe_days(df=interaction_swipe.copy(), side='to')\n",
    "\n",
    "from_total_swipe_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the weekday, weekend interaction of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def weekend_interaction(df, side):\n",
    "    '''\n",
    "    This function is about gettting the count of total swipes right/left during the weekdays and weekends by \"from\".\n",
    "    Likewise how many time \"to\" was swipped left or right during the during the weekday and weekends.\n",
    "    '''\n",
    "    temp = df.groupby([side, 'weekends']).agg(weekend_interaction_count = ('weekends', 'count')).reset_index()\n",
    "    temp = temp.pivot(index=side, columns='weekends', values=['weekend_interaction_count']).reset_index().fillna(0)\n",
    "    temp.columns = [side, side+'_weekday_interaction_count', side+'_weekend_interaction_count']\n",
    "    \n",
    "    total = temp[side +'_weekday_interaction_count'] + temp[side +'_weekend_interaction_count']\n",
    "    temp[side +'_weekday_interaction_percentage'] = temp[side+'_weekday_interaction_count']/total\n",
    "    temp[side +'_weekend_interaction_percentage'] = temp[side+'_weekend_interaction_count']/total\n",
    "    \n",
    "    return temp\n",
    "    \n",
    "from_weekend_interaction = weekend_interaction(df=interaction_swipe.copy(), side='from')\n",
    "to_weekend_interaction = weekend_interaction(df=interaction_swipe.copy(), side='to')\n",
    "to_weekend_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the dayswise interaction of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def day_wise_count(df, side):\n",
    "    temp = df.groupby([side, 'weekday']).agg(day_wise_count=('weekday', 'count')).reset_index()\n",
    "    \n",
    "    temp = temp.pivot(index=side, columns='weekday', values=['day_wise_count']).reset_index().fillna(0)\n",
    "    temp.columns = [side, \n",
    "                    side+'_weekday0_interaction_count', \n",
    "                    side+'_weekday1_interaction_count',\n",
    "                    side+'_weekday2_interaction_count',\n",
    "                    side+'_weekday3_interaction_count',\n",
    "                    side+'_weekday4_interaction_count',\n",
    "                    side+'_weekday5_interaction_count',\n",
    "                    side+'_weekday6_interaction_count'\n",
    "                   ]\n",
    "    \n",
    "    total = temp[[side+'_weekday0_interaction_count', side+'_weekday1_interaction_count',\n",
    "                  side+'_weekday2_interaction_count', side+'_weekday3_interaction_count',\n",
    "                  side+'_weekday4_interaction_count', side+'_weekday5_interaction_count',\n",
    "                  side+'_weekday6_interaction_count']].sum(axis=1)\n",
    "    \n",
    "    temp[side +'_weekday0_interaction_percentage'] = temp[side+'_weekday0_interaction_count']/total\n",
    "    temp[side +'_weekday1_interaction_percentage'] = temp[side+'_weekday1_interaction_count']/total\n",
    "    temp[side +'_weekday2_interaction_percentage'] = temp[side+'_weekday2_interaction_count']/total\n",
    "    temp[side +'_weekday3_interaction_percentage'] = temp[side+'_weekday3_interaction_count']/total\n",
    "    temp[side +'_weekday4_interaction_percentage'] = temp[side+'_weekday4_interaction_count']/total\n",
    "    temp[side +'_weekday5_interaction_percentage'] = temp[side+'_weekday5_interaction_count']/total\n",
    "    temp[side +'_weekday6_interaction_percentage'] = temp[side+'_weekday6_interaction_count']/total\n",
    "    \n",
    "    return temp\n",
    "\n",
    "from_daywise_interaction = day_wise_count(df=interaction_swipe.copy(), side='from')\n",
    "to_daywise_interaction = day_wise_count(df=interaction_swipe.copy(), side='to')\n",
    "from_daywise_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the swipe left, right count, percentage and total swipe count of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def swipe_counts(df, side):\n",
    "    'This function is how many times a user either in from or to has the swiped -1 or 1'\n",
    "    \n",
    "    df = df.groupby([side, 'swipe_status']).agg(total_swipes= (side, 'count')).reset_index()\n",
    "    \n",
    "    temp = df.pivot(index=side, columns='swipe_status', values=['total_swipes']).reset_index()\n",
    "    temp.columns = [side, side+'_swipe_left_count', side+'_swipe_right_count']\n",
    "    \n",
    "    temp[side +'_total_swipe_counts'] = temp[[side+'_swipe_left_count', side+'_swipe_right_count']].sum(axis=1)\n",
    "    \n",
    "    temp[side +'_left_percentage'] = temp[side+'_swipe_left_count']/temp[side +'_total_swipe_counts']\n",
    "    temp[side +'_right_percentage'] = temp[side+'_swipe_right_count']/temp[side +'_total_swipe_counts']\n",
    "    \n",
    "    temp.fillna(0, inplace=True)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "interaction_from_swipe_status_counts = swipe_counts(df=interaction_swipe, side='from')\n",
    "interaction_to_swipe_status_counts = swipe_counts(df=interaction_swipe, side='to')\n",
    "\n",
    "print(interaction_from_swipe_status_counts.shape, interaction_to_swipe_status_counts.shape)\n",
    "interaction_from_swipe_status_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the time stats of swipes of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def time_since_swipe_stat(df, side):\n",
    "    'This function is to get the timestamp stat between the swipe interaction of \"from\" and \"to\" user '\n",
    "    'which can be either 1 or -1'\n",
    "    \n",
    "    # Sorting it by form and timestamp\n",
    "    df = df.sort_values([side, 'timestamp'])\n",
    "    df['lag_time'] = df.groupby([side]).timestamp.shift(1)\n",
    "    df['time_since_last_swipe'] = df.timestamp - df.lag_time\n",
    "    df['time_since_last_swipe'] = df['time_since_last_swipe'].dt.seconds\n",
    "    df['time_since_last_swipe'] = df['time_since_last_swipe'].fillna(0)\n",
    "    df.drop(['lag_time'], inplace=True, axis=1)\n",
    "\n",
    "    df = df.groupby([side]).agg(mean_time_since_last_swipe=('time_since_last_swipe', 'mean'),\n",
    "                                median_time_since_last_swipe=('time_since_last_swipe', 'median'),\n",
    "                                max_time_since_last_swipe=('time_since_last_swipe', 'max')).reset_index()\n",
    "    df.columns = [side, side+'_mean_time_since_last_swipe',\n",
    "                  side+'_median_time_since_last_swipe', \n",
    "                  side+'_max_time_since_last_swipe']\n",
    "\n",
    "    return df\n",
    "\n",
    "from_swipe_time_stat = time_since_swipe_stat(df=interaction_swipe.copy(), side='from')\n",
    "to_swipe_time_stat = time_since_swipe_stat(df=interaction_swipe.copy(), side='to')\n",
    "\n",
    "print(from_swipe_time_stat.shape, to_swipe_time_stat.shape)\n",
    "from_swipe_time_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the time since last left or right swipes of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def time_since_left_right_swipe_stat(df, side):\n",
    "    '''\n",
    "    This function is to get the timestamp stat between the swipe interaction of \"from\" and \"to\" user\n",
    "    from their last 1 or -1\n",
    "    '''\n",
    "    \n",
    "    # Sorting it by form and timestamp\n",
    "    df = df.sort_values([side, 'swipe_status', 'timestamp'])\n",
    "\n",
    "    df['lag_time'] = df.groupby([side, 'swipe_status']).timestamp.shift(1)\n",
    "    df['time_since_last_swipe'] = df.timestamp - df.lag_time\n",
    "\n",
    "    df['time_since_last_swipe'] = df['time_since_last_swipe'].dt.seconds\n",
    "    df['time_since_last_swipe'] = df['time_since_last_swipe'].fillna(0)\n",
    "\n",
    "    df = df.groupby([side, 'swipe_status']).agg(mean_time_since_last_swipe=('time_since_last_swipe', 'mean'),\n",
    "                                                median_time_since_last_swipe=('time_since_last_swipe', 'median'),\n",
    "                                                max_time_since_last_swipe=('time_since_last_swipe', 'max')).reset_index()\n",
    "\n",
    "    df = df.pivot(index=side, columns='swipe_status', values=['mean_time_since_last_swipe',\n",
    "                                                              'median_time_since_last_swipe',\n",
    "                                                              'max_time_since_last_swipe']).reset_index()\n",
    "    \n",
    "    df.columns = [side, side+'_swipe_left_mean_time', side+'_swipe_right_mean_time',\n",
    "                  side+'_swipe_left_median_time', side+'_swipe_right_median_time',\n",
    "                  side+'_swipe_left_max_time', side+'_swipe_right_max_time']\n",
    "\n",
    "    return df\n",
    "\n",
    "from_swipe_time_since_left_right = time_since_left_right_swipe_stat(df=interaction_swipe.copy(), side='from')\n",
    "to_swipe_time_since_left_right = time_since_left_right_swipe_stat(df=interaction_swipe.copy(), side='to')\n",
    "\n",
    "print(from_swipe_time_since_left_right.shape, to_swipe_time_since_left_right.shape)\n",
    "from_swipe_time_since_left_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the users age in the app from interaction swipe dataset\")\n",
    "\n",
    "def user_swipe_age_in_app(df, side):\n",
    "    df = df.groupby([side]).agg(min_time = ('timestamp', 'min'),\n",
    "                                max_time = ('timestamp', 'max')).reset_index()\n",
    "    df[side+'_swipe_age_in_app'] = (df.max_time - df.min_time).dt.seconds\n",
    "    df = df[[side, side + '_swipe_age_in_app']].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "from_user_age_in_app = user_swipe_age_in_app(df=interaction_swipe.copy(), side='from')\n",
    "to_user_age_in_app = user_swipe_age_in_app(df=interaction_swipe.copy(), side='to')\n",
    "\n",
    "to_user_age_in_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the swipe interaction from and to stats\n",
    "\n",
    "to_stats = to_swipe_time_stat.merge(to_swipe_time_since_left_right, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(interaction_to_swipe_status_counts, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(to_user_age_in_app, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(to_weekend_interaction, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(to_daywise_interaction, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(to_total_swipe_days, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "to_stats = to_stats.merge(to_first_last_swipe_year, left_on='to', right_on='to', how='inner')\n",
    "print(to_stats.shape)\n",
    "print(\"\")\n",
    "\n",
    "from_stats = from_swipe_time_stat.merge(from_swipe_time_since_left_right, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(interaction_from_swipe_status_counts, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(from_user_age_in_app, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(from_weekend_interaction, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(from_daywise_interaction, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(from_total_swipe_days, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n",
    "from_stats = from_stats.merge(from_first_last_swipe_year, left_on='from', right_on='from', how='inner')\n",
    "print(from_stats.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction review_strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_review_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_interaction_review_strength_preprocess(df):\n",
    "    \n",
    "    df = pd.get_dummies(df.set_index('from-to')['strength_id']).add_prefix('rev_strength_').sum(level=0)\n",
    "    df = df.reset_index()\n",
    "    df['total_interaction_review_strength_assessed'] = df.iloc[:, 1:].sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "interaction_review_strength = total_interaction_review_strength_preprocess(df=interaction_review_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_review_strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction review comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_review_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ages[user_ages.age<18] = 18\n",
    "user_ages[user_ages.age>55] = 55\n",
    "user_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User educations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_educations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_education_preprocess(df):\n",
    "    print(\"Before dropping duplicates\", df.shape)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.sort_values(['user_id', 'degree_id']).reset_index(drop=True)\n",
    "    print(\"After dropping duplicates\",df.shape)\n",
    "    \n",
    "    # Filling the NA with forward fill\n",
    "    df['temp_degree_id'] = df.groupby(['user_id']).degree_id.ffill()\n",
    "    df.temp_degree_id[df.degree_id.isnull()] = df['temp_degree_id']+1\n",
    "\n",
    "    # Filling the rest of the Null values left\n",
    "    df['temp_deg_count'] = df.groupby(['user_id']).user_id.apply(lambda x: x.expanding().count())\n",
    "    df['final_degree_id'] = np.where(df.temp_degree_id.isnull(), \n",
    "                                     df.temp_deg_count, df.temp_degree_id)\n",
    "    df.drop(['temp_degree_id', 'temp_deg_count', 'degree_id'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "user_educations = user_education_preprocess(df=user_educations)\n",
    "user_educations.head(20)\n",
    "\n",
    "user_educations_v2 = user_educations.groupby(['user_id']).agg(education_count=('user_id','count'),\n",
    "                                                              unique_school_count=('school_id','nunique'),\n",
    "                                                              unique_degree_count=('final_degree_id','nunique')).reset_index()\n",
    "\n",
    "user_educations_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_purpose_preprocess(df):\n",
    "    # From our EDA we saw there were values > 1. So let's fill all of them as 1 for now \n",
    "    df.iloc[:, 1:-1] = df.iloc[:, 1:16].replace([2, 3, 4, 5, 6], \n",
    "                                                [1, 1, 1, 1, 1])\n",
    "    df['total_purpose'] = df.iloc[:, 1:16].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "user_purpose_v2 = user_purpose_preprocess(df=user_purpose.copy())\n",
    "user_purpose_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_self_intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_self_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sessions.timestamp = pd.to_datetime(user_sessions.timestamp)\n",
    "\n",
    "user_sessions['hour'] = user_sessions.timestamp.dt.hour\n",
    "user_sessions['year'] = user_sessions.timestamp.dt.year\n",
    "user_sessions['month'] = user_sessions.timestamp.dt.month\n",
    "user_sessions['day'] = user_sessions.timestamp.dt.day\n",
    "user_sessions['weekday'] = user_sessions.timestamp.dt.weekday\n",
    "user_sessions['weekends'] = np.where(user_sessions.weekday>=5, 1, 0)\n",
    "user_sessions.dropna(inplace=True)\n",
    "\n",
    "user_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the users session age in the app from session dataset\")\n",
    "\n",
    "def user_session_age_in_app(df):\n",
    "    df = df.groupby(['user_id']).agg(min_time = ('timestamp', 'min'),\n",
    "                                     max_time = ('timestamp', 'max')).reset_index()\n",
    "    df['session_age_in_app'] = (df.max_time - df.min_time).dt.seconds\n",
    "    df = df[['user_id', 'session_age_in_app']].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "user_session_age_in_app = user_session_age_in_app(df=user_sessions.copy())\n",
    "user_session_age_in_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the swipe left, right count, percentage and total swipe count of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def get_session_counts(df):\n",
    "    'This function is how many times a user had a session'\n",
    "    \n",
    "    temp = df.groupby(['user_id']).agg(total_session_count= ('user_id', 'count')).reset_index()\n",
    "    temp.fillna(0, inplace=True)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "user_session_counts = get_session_counts(df=user_sessions.copy())\n",
    "\n",
    "user_session_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the First and last session of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def first_last_session_year(df):\n",
    "    temp = df.groupby(['user_id']).agg(first_session_year = ('year', 'min'),\n",
    "                                       last_session_year = ('year', 'max')).reset_index()\n",
    "    temp['session_year_difference'] = temp.last_session_year - temp.first_session_year\n",
    "    temp.columns = ['user_id', 'first_session_year', 'last_session_year', 'session_year_difference']\n",
    "    return temp\n",
    "\n",
    "user_first_last_session_year = first_last_session_year(df=user_sessions.copy())\n",
    "\n",
    "user_first_last_session_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the total swipe days of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def total_session_days(df):\n",
    "    temp = df.groupby(['user_id', 'year', 'month']).agg(unique_days = ('day', 'nunique')).reset_index()\n",
    "    temp = temp.groupby(['user_id']).agg(total_swipe_days = ('unique_days', 'sum')).reset_index()\n",
    "    temp.columns = ['user_id', 'total_session_days']\n",
    "    return temp\n",
    "\n",
    "user_total_session_days = total_session_days(df=user_sessions.copy())\n",
    "\n",
    "user_total_session_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_time_stats(df):\n",
    "    \n",
    "    # Sorting it by form and timestamp\n",
    "    df = df.sort_values(['user_id', 'timestamp'])\n",
    "    df['lag_time'] = df.groupby(['user_id']).timestamp.shift(1)\n",
    "\n",
    "    df['time_since_last_session'] = df.timestamp - df.lag_time\n",
    "    df['time_since_last_session'] = df['time_since_last_session'].dt.seconds\n",
    "    df['time_since_last_session'] = df['time_since_last_session'].fillna(0)\n",
    "    df.drop(['lag_time'], inplace=True, axis=1)\n",
    "\n",
    "    df = df.groupby(['user_id']).agg(mean_session_time=('time_since_last_session', 'mean'),\n",
    "                                     median_session_time=('time_since_last_session', 'median'),\n",
    "                                     max_session_time=('time_since_last_session', 'max')).reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "user_session_stats = session_time_stats(df=user_sessions.copy())\n",
    "user_session_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_skills_preprocess(df):\n",
    "    print(df.shape)\n",
    "    df = df.loc[~df.duplicated(),]\n",
    "    print(df.shape)\n",
    "    df = df.groupby(['user_id']).agg(total_skills = ('skill_id', 'count')).reset_index()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "user_skills_v2=user_skills_preprocess(df=user_skills)\n",
    "user_skills_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_strength_preprocess(df):\n",
    "    df['total_strength_votes'] = df.iloc[:, 1:].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "user_strengths_v2 = user_strength_preprocess(df=user_strengths.copy())\n",
    "user_strengths_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_works_preprocess(df):\n",
    "    print(df.shape)\n",
    "    df = df.sort_values(['user_id', 'company_id', 'industry_id', 'over_1000_employees']).reset_index(drop=True)\n",
    "    df = df.loc[~df.duplicated(), ].reset_index(drop=True)\n",
    "    \n",
    "    dup_rec = df[['user_id', 'company_id', 'industry_id']].duplicated()\n",
    "    null_index = df[dup_rec].index[df[dup_rec].over_1000_employees.isnull()]\n",
    "\n",
    "    df = df.loc[~df.index.isin(null_index), :].reset_index(drop=True)    \n",
    "    print(df.shape)\n",
    "    \n",
    "    df = df.groupby(['user_id']).agg(uniq_companies_worked=('company_id','nunique'),\n",
    "                                     uniq_industries_worked=('industry_id','nunique'),\n",
    "                                     total_compaies_employ_gr_1000=('over_1000_employees', 'sum')).reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "user_works_v2 = user_works_preprocess(df=user_works.copy())\n",
    "user_works_v2.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age:\", user_ages.shape, \n",
    "      \"Education:\",  user_educations_v2.shape,\n",
    "      \"Purpose:\", user_purpose_v2.shape, \n",
    "      \"User skills:\", user_skills_v2.shape, \n",
    "      \"Strength:\",user_strengths_v2.shape, \n",
    "      \"Works:\", user_works_v2.shape, #user_self_intro.shape, user_sessions.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all the users data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merging the age and education\")\n",
    "user_master_df = pd.merge(user_ages, user_educations_v2, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the purpose\")\n",
    "user_master_df = pd.merge(user_master_df, user_purpose_v2, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the User Session age\")\n",
    "user_master_df = pd.merge(user_master_df, user_session_age_in_app, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the Session count\")\n",
    "user_master_df = pd.merge(user_master_df, user_session_counts, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"Merging the Session first last year\")\n",
    "user_master_df = pd.merge(user_master_df, user_first_last_session_year, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the Session unique days\")\n",
    "user_master_df = pd.merge(user_master_df, user_total_session_days, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the Session time stats\")\n",
    "user_master_df = pd.merge(user_master_df, user_session_stats, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the skills\")\n",
    "user_master_df = pd.merge(user_master_df, user_skills_v2, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the strength\")\n",
    "user_master_df = pd.merge(user_master_df, user_strengths_v2, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the user work\")\n",
    "user_master_df = pd.merge(user_master_df, user_works_v2, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Merging the user intro\")\n",
    "user_master_df = pd.merge(user_master_df, user_self_intro, left_on=['user_id'],right_on=['user_id'], how='outer')\n",
    "print(user_master_df.shape)\n",
    "\n",
    "\n",
    "# Merging the user intro\n",
    "# (46774, 345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all the data to train and test prod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the Interaction swipe stats with train and test\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "\n",
    "train_prod = train_prod.merge(to_stats, left_on='to', right_on='to', how='left')\n",
    "train_prod = train_prod.merge(from_stats, left_on='from', right_on='from', how='left')\n",
    "\n",
    "test_prod = test_prod.merge(to_stats, left_on='to', right_on='to', how='left')\n",
    "test_prod = test_prod.merge(from_stats, left_on='from', right_on='from', how='left')\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "\n",
    "# Combining all interaction swipe count between the same from-to user to the train and test set\n",
    "train_prod = train_prod.merge(interaction_from_to_swipe_counts, left_on = ['from', 'to'], right_on = ['from', 'to'], how='left')\n",
    "test_prod = test_prod.merge(interaction_from_to_swipe_counts, left_on = ['from', 'to'], right_on = ['from', 'to'], how='left')\n",
    "\n",
    "# Combining the interaction_review_strength\n",
    "train_prod = train_prod.merge(interaction_review_strength, left_on = 'from-to', right_on='from-to', how='left')\n",
    "test_prod = test_prod.merge(interaction_review_strength, left_on = 'from-to', right_on='from-to', how='left')\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "\n",
    "# #Combining the interaction review comments\n",
    "train_prod = train_prod.merge(interaction_review_comments, left_on = 'from-to', right_on='from-to', how='left')\n",
    "test_prod = test_prod.merge(interaction_review_comments, left_on = 'from-to', right_on='from-to', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_user_data = user_master_df.copy()\n",
    "from_user_data = from_user_data.add_prefix(\"from_\")\n",
    "\n",
    "to_user_data = user_master_df.copy()\n",
    "to_user_data = to_user_data.add_prefix(\"to_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_prod = train_prod.merge(from_user_data, left_on = 'from', right_on='from_user_id', how='left')\n",
    "print(train_prod.shape)\n",
    "train_prod = train_prod.merge(to_user_data, left_on = 'to', right_on='to_user_id', how='left')\n",
    "print(train_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prod = test_prod.merge(from_user_data, left_on = 'from', right_on='from_user_id', how='left')\n",
    "print(test_prod.shape)\n",
    "test_prod = test_prod.merge(to_user_data, left_on = 'to', right_on='to_user_id', how='left')\n",
    "print(test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod.drop(['from_user_id','to_user_id'], axis=1, inplace=True)\n",
    "print(train_prod.shape)\n",
    "\n",
    "test_prod.drop(['from_user_id','to_user_id'], axis=1, inplace=True)\n",
    "print(test_prod.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(user_df, features_df, selected_columns):\n",
    "    similairty = []\n",
    "    from_to=[]\n",
    "    for i, dataframe in tqdm(user_df[['from-to', 'from', 'to']].iterrows(), total=len(user_df)):\n",
    "        #print(i)\n",
    "        try:\n",
    "            from_user = dataframe['from']\n",
    "            to_user = dataframe['to']\n",
    "            #print(from_user, to_user)\n",
    "\n",
    "            temp = features_df.loc[features_df.user_id.isin([from_user, to_user]), selected_columns].copy()\n",
    "            #print(temp.shape)\n",
    "            similarity_score = cosine_similarity(temp)[0, 1]\n",
    "\n",
    "            from_to.append(dataframe['from-to'])\n",
    "            similairty.append(similarity_score)\n",
    "    \n",
    "        except (IndexError, ValueError) as error:\n",
    "            #print(\"These from-to users are not present in the self intro:\", from_user, to_user)\n",
    "            #print(\"error message:\", error)\n",
    "            from_to.append(dataframe['from-to'])\n",
    "            similairty.append(0)\n",
    "                \n",
    "    similairy_df = pd.DataFrame({'from-to':from_to, \n",
    "                                  'cosine_similarity':similairty})\n",
    "    return similairy_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = user_self_intro.columns[user_self_intro.columns.str.contains('features_df')]\n",
    "\n",
    "train_prod_user_intro_cosine_similarity = get_cosine_similarity(user_df=train_prod, features_df=user_self_intro, selected_columns=selected_cols)\n",
    "print(\"\")\n",
    "test_prod_user_intro_cosine_similarity = get_cosine_similarity(user_df=test_prod, features_df=user_self_intro, selected_columns=selected_cols)\n",
    "\n",
    "train_prod_user_intro_cosine_similarity.to_csv(\"../data/train_prod_user_intro_cosine_similarity.csv\", index=False)\n",
    "test_prod_user_intro_cosine_similarity.to_csv(\"../data/test_prod_user_intro_cosine_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_user_intro_cosine_similarity = pd.read_csv(\"../data/train_prod_user_intro_cosine_similarity.csv\")\n",
    "test_prod_user_intro_cosine_similarity = pd.read_csv(\"../data/test_prod_user_intro_cosine_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod = train_prod.merge(train_prod_user_intro_cosine_similarity, \n",
    "                              left_on = 'from-to',\n",
    "                              right_on = 'from-to', how='left')\n",
    "test_prod = test_prod.merge(test_prod_user_intro_cosine_similarity, \n",
    "                            left_on = 'from-to',\n",
    "                            right_on = 'from-to', how='left')\n",
    "\n",
    "train_prod.rename(columns={'cosine_similarity':'user_intro_cosine_similarity'}, inplace=True)\n",
    "test_prod.rename(columns={'cosine_similarity':'user_intro_cosine_similarity'}, inplace=True)\n",
    "\n",
    "print(train_prod.shape)\n",
    "print(test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = selected_cols = user_purpose.columns[user_purpose.columns.str.contains('purpose_id_')]\n",
    "\n",
    "print(\"Running the train similarity\")\n",
    "train_prod_purpose_cosine_similarity = get_cosine_similarity(user_df=train_prod, features_df=user_purpose, selected_columns=selected_cols)\n",
    "print(\"\")\n",
    "print(\"Running the test similarity\")\n",
    "test_prod_purpose_cosine_similarity = get_cosine_similarity(user_df=test_prod, features_df=user_purpose, selected_columns=selected_cols)\n",
    "\n",
    "train_prod_purpose_cosine_similarity.to_csv(\"../data/train_prod_purpose_cosine_similarity.csv\", index=False)\n",
    "test_prod_purpose_cosine_similarity.to_csv(\"../data/test_prod_purpose_cosine_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_purpose_cosine_similarity = pd.read_csv(\"../data/train_prod_purpose_cosine_similarity.csv\")\n",
    "test_prod_purpose_cosine_similarity = pd.read_csv(\"../data/test_prod_purpose_cosine_similarity.csv\")\n",
    "\n",
    "train_prod = train_prod.merge(train_prod_purpose_cosine_similarity, \n",
    "                              left_on = 'from-to',\n",
    "                              right_on = 'from-to', how='left')\n",
    "test_prod = test_prod.merge(test_prod_purpose_cosine_similarity, \n",
    "                            left_on = 'from-to',\n",
    "                            right_on = 'from-to', how='left')\n",
    "\n",
    "train_prod.rename(columns={'cosine_similarity':'user_purpose_cosine_similarity'}, inplace=True)\n",
    "test_prod.rename(columns={'cosine_similarity':'user_purpose_cosine_similarity'}, inplace=True)\n",
    "\n",
    "print(train_prod.shape)\n",
    "print(test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_review_comments[['from', 'to']] = interaction_review_comments['from-to'].str.split(\"-\", expand=True).astype('int')\n",
    "rev_columns = interaction_review_comments.columns[interaction_review_comments.columns.str.contains(\"review_comment_\")].tolist()\n",
    "interaction_review_comments[['from-to', 'from', 'to'] + rev_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_comment_count(df, side):\n",
    "    '''\n",
    "    This function is about gettting the count of total reviews provided by \"from\".\n",
    "    Likewise how many reviews were received by \"to\".\n",
    "    '''\n",
    "    temp = df.groupby([side]).agg(review_comments_count = (side, 'count')).reset_index()\n",
    "    temp.columns = [side, side+\"_review_comments_count\"]\n",
    "\n",
    "    return temp\n",
    "\n",
    "from_review_count = review_comment_count(df=interaction_review_comments, side='from')\n",
    "to_review_count = review_comment_count(df=interaction_review_comments, side='to')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before merge\", train_prod.shape, test_prod.shape)\n",
    "train_prod = train_prod.merge(from_review_count, \n",
    "                             left_on = 'from', right_on = 'from',\n",
    "                             how='left')\n",
    "train_prod = train_prod.merge(to_review_count, \n",
    "                             left_on = 'to', right_on = 'to',\n",
    "                             how='left')\n",
    "\n",
    "test_prod = test_prod.merge(from_review_count, \n",
    "                             left_on = 'from', right_on = 'from',\n",
    "                             how='left')\n",
    "test_prod = test_prod.merge(to_review_count, \n",
    "                             left_on = 'to', right_on = 'to',\n",
    "                             how='left')\n",
    "\n",
    "print(\"After merge\",train_prod.shape, test_prod.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_purpose_count(user_df, purpose_df, purpose_columns):\n",
    "    from_to=[]\n",
    "    common_purpose=[]\n",
    "    \n",
    "    common_interested_purpose=[]\n",
    "    common_uninterested_purpose=[]\n",
    "    for i, dataframe in tqdm(user_df[['from-to', 'from', 'to']].iterrows(), total=len(user_df)):\n",
    "\n",
    "        from_user = dataframe['from']\n",
    "        to_user = dataframe['to']\n",
    "\n",
    "        from_temp = purpose_df.loc[purpose_df.user_id.isin([from_user]), purpose_columns].reset_index(drop=True)\n",
    "        to_temp = purpose_df.loc[purpose_df.user_id.isin([to_user]), purpose_columns].reset_index(drop=True)\n",
    "        \n",
    "        if ((from_temp.shape[0] != 0) & (to_temp.shape[0] != 0)):\n",
    "            \n",
    "            match_from_to_purpose = (from_temp + to_temp)\n",
    "            \n",
    "            match_same_interest_purpose = (match_from_to_purpose==2)\n",
    "            common_interest_purpose_count = match_same_interest_purpose.sum(axis=1).values[0]\n",
    "\n",
    "            match_same_uninterest_purpose = (match_from_to_purpose==0)\n",
    "            common_uninterest_purpose_count = match_same_uninterest_purpose.sum(axis=1).values[0]\n",
    "            \n",
    "            from_to.append(dataframe['from-to'])        \n",
    "            common_interested_purpose.append(common_interest_purpose_count)\n",
    "            common_uninterested_purpose.append(common_uninterest_purpose_count)\n",
    "            \n",
    "        else:\n",
    "            from_to.append(dataframe['from-to'])        \n",
    "            common_interested_purpose.append(-999)\n",
    "            common_uninterested_purpose.append(-999)\n",
    "\n",
    "    purpose_df = pd.DataFrame({'from-to': from_to, \n",
    "                               'common_interested_purpose': common_interested_purpose,\n",
    "                               'common_uninterested_purpose': common_uninterested_purpose,})\n",
    "    \n",
    "    return purpose_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_columns = user_purpose.columns[user_purpose.columns.str.contains('purpose')]\n",
    "\n",
    "train_purpose_match_df = get_common_purpose_count(user_df=train_prod.copy(), purpose_df=user_purpose.copy(), purpose_columns=sel_columns)\n",
    "test_purpose_match_df = get_common_purpose_count(user_df=test_prod.copy(), purpose_df=user_purpose.copy(), purpose_columns=sel_columns)\n",
    "\n",
    "train_purpose_match_df.to_csv(\"../data/train_purpose_match_df.csv\", index=False)\n",
    "test_purpose_match_df.to_csv(\"../data/test_purpose_match_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purpose_match_df = pd.read_csv(\"../data/train_purpose_match_df.csv\")\n",
    "test_purpose_match_df = pd.read_csv(\"../data/test_purpose_match_df.csv\")\n",
    "\n",
    "train_prod = train_prod.merge(train_purpose_match_df, on='from-to', how='left')\n",
    "test_prod = test_prod.merge(test_purpose_match_df, on='from-to', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_users_swiped(interaction, df):\n",
    "    \n",
    "    interaction_right = interaction.loc[interaction.swipe_status==1, :].copy()\n",
    "    interaction_left  = interaction.loc[interaction.swipe_status==-1, :].copy()\n",
    "    \n",
    "    from_swiped_right_users =  dict(interaction_right.groupby('from')['to'].apply(list))\n",
    "    from_swiped_left_users =  dict(interaction_left.groupby('from')['to'].apply(list))\n",
    "    \n",
    "    #print(from_swiped_right_users)\n",
    "    #print(from_swiped_left_users)\n",
    "    \n",
    "    common_swipes_right=[]\n",
    "    common_swipes_left=[]\n",
    "    common_from_left_to_right_swiped=[]\n",
    "    common_from_right_to_left_swiped=[]\n",
    "    from_to_list = []\n",
    "    \n",
    "    for i, dataframe in tqdm(df[['from-to', 'from', 'to']].iterrows(), total=len(df)):\n",
    "        from_to = dataframe['from-to']\n",
    "        from_user = dataframe['from']\n",
    "        to_user = dataframe['to']\n",
    "        \n",
    "        try:\n",
    "            common_users_right_swiped = len(np.intersect1d(from_swiped_right_users[from_user], from_swiped_right_users[to_user]))\n",
    "            common_swipes_right.append(common_users_right_swiped)\n",
    "        except KeyError:\n",
    "            common_swipes_right.append(0)\n",
    "        \n",
    "        try:\n",
    "            common_users_left_swiped = len(np.intersect1d(from_swiped_left_users[from_user], from_swiped_left_users[to_user]))\n",
    "            common_swipes_left.append(common_users_left_swiped)\n",
    "        except KeyError:\n",
    "            common_swipes_left.append(0)\n",
    "        \n",
    "        try:\n",
    "            common_users_from_left_to_right_swiped = len(np.intersect1d(from_swiped_left_users[from_user], from_swiped_right_users[to_user]))\n",
    "            common_from_left_to_right_swiped.append(common_users_from_left_to_right_swiped)\n",
    "        except KeyError:\n",
    "            common_from_left_to_right_swiped.append(0)\n",
    "        \n",
    "        try:\n",
    "            common_users_from_right_to_left_swiped = len(np.intersect1d(from_swiped_right_users[from_user], from_swiped_left_users[to_user]))\n",
    "            common_from_right_to_left_swiped.append(common_users_from_right_to_left_swiped)\n",
    "        except KeyError:\n",
    "            common_from_right_to_left_swiped.append(0)\n",
    "        \n",
    "        from_to_list.append(from_to)\n",
    "\n",
    "    common_swipes = pd.DataFrame({'from-to': from_to_list, \n",
    "                                  'common_users_swiped_right': common_swipes_right,\n",
    "                                  'common_users_swiped_left': common_swipes_left,\n",
    "                                  'common_users_from_left_to_right_swiped': common_from_left_to_right_swiped,\n",
    "                                  'common_users_from_right_to_left_swiped': common_from_right_to_left_swiped})\n",
    "\n",
    "    \n",
    "    return common_swipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_interaction_df = interaction_swipe[['from', 'to', 'swipe_status']].drop_duplicates().copy()\n",
    "\n",
    "train_common_users_swiped = common_users_swiped(interaction=small_interaction_df.copy(), df = train_prod.copy())\n",
    "test_common_users_swiped = common_users_swiped(interaction= small_interaction_df.copy(), df = test_prod.copy())\n",
    "\n",
    "train_common_users_swiped.to_csv(\"../data/train_common_users_swiped_v2.csv\", index=False)\n",
    "test_common_users_swiped.to_csv(\"../data/test_common_users_swiped_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_common_users_swiped = pd.read_csv(\"../data/train_common_users_swiped_v2.csv\")\n",
    "test_common_users_swiped = pd.read_csv(\"../data/test_common_users_swiped_v2.csv\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "train_prod = train_prod.merge(train_common_users_swiped, on = 'from-to', how='left')\n",
    "test_prod = test_prod.merge(test_common_users_swiped, on = 'from-to', how='left')\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_users_session_time(sessions, df):\n",
    "    from_to_list=[]\n",
    "    \n",
    "    same_day_session_count = []\n",
    "    same_hour_session_count = []\n",
    "    for i, dataframe in tqdm(df[['from-to', 'from', 'to']].iterrows(), total=len(df)):\n",
    "        from_to = dataframe['from-to']\n",
    "        from_user = dataframe['from']\n",
    "        to_user = dataframe['to']\n",
    "        \n",
    "        sessions_small = sessions.loc[sessions.user_id.isin([from_user, to_user]), :].copy()\n",
    "        \n",
    "        col = ['year', 'month', 'day']\n",
    "        same_day_login_count = sessions_small[['user_id'] + col].drop_duplicates().copy()\n",
    "        same_day_login_count = same_day_login_count[col].duplicated().sum()\n",
    "        \n",
    "        col = ['year', 'month', 'day', 'hour']\n",
    "        same_hour_login_count = sessions_small[['user_id'] + col].drop_duplicates().copy()\n",
    "        same_hour_login_count = same_hour_login_count[col].duplicated().sum()\n",
    "        \n",
    "        same_day_session_count.append(same_day_login_count)\n",
    "        same_hour_session_count.append(same_hour_login_count)\n",
    "        from_to_list.append(from_to)\n",
    "        \n",
    "    common_user_session = pd.DataFrame({'from-to': from_to_list, \n",
    "                                        'same_day_session_count':same_day_session_count,\n",
    "                                        'same_hour_session_count': same_hour_session_count}\n",
    "                                       )\n",
    "\n",
    "    return common_user_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"User session shape\", user_sessions.shape)\n",
    "uniq_user_sessions = user_sessions[['user_id', 'year', 'month', 'day', 'hour']].drop_duplicates().copy()\n",
    "print(\"Unique User session shape\", uniq_user_sessions.shape)\n",
    "\n",
    "train_prod_common_sessions = common_users_session_time(sessions=uniq_user_sessions.copy(), df=train_prod.loc[0:100, :].copy())\n",
    "test_prod_common_sessions = common_users_session_time(sessions=uniq_user_sessions.copy(), df=test_prod.loc[0:10, :].copy())\n",
    "\n",
    "train_prod_common_sessions.to_csv(\"../data/train_prod_common_sessions.csv\", index=False)\n",
    "test_prod_common_sessions.to_csv(\"../data/test_prod_common_sessions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_common_sessions = pd.read_csv(\"../data/train_prod_common_sessions.csv\")\n",
    "test_prod_common_sessions = pd.read_csv(\"../data/test_prod_common_sessions.csv\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "train_prod = train_prod.merge(train_prod_common_sessions, on = 'from-to', how='left')\n",
    "test_prod = test_prod.merge(test_prod_common_sessions, on = 'from-to', how='left')\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_purpose(user_df, purpose_df, purpose_columns):\n",
    "    from_to=[]\n",
    "\n",
    "    common_interested_purpose_array = np.empty(shape=(0, 15))\n",
    "    common_uninterested_purpose_array = np.empty(shape=(0, 15))\n",
    "    uncommon_interest_array = np.empty(shape=(0, 15))\n",
    "    no_user_data = np.zeros(shape=(1, 15))\n",
    "    \n",
    "    for i, dataframe in tqdm(user_df[['from-to', 'from', 'to']].iterrows(), total=len(user_df)):\n",
    "\n",
    "        from_to.append(dataframe['from-to'])\n",
    "        from_user = dataframe['from']\n",
    "        to_user = dataframe['to']\n",
    "\n",
    "        from_temp = purpose_df.loc[purpose_df.user_id.isin([from_user]), purpose_columns].reset_index(drop=True)\n",
    "        to_temp = purpose_df.loc[purpose_df.user_id.isin([to_user]), purpose_columns].reset_index(drop=True)\n",
    "        \n",
    "        if ((from_temp.shape[0] != 0) & (to_temp.shape[0] != 0)):            \n",
    "            match_from_to_purpose = (from_temp + to_temp)\n",
    "            \n",
    "            temp = (match_from_to_purpose==2)\n",
    "            common_interested_purpose_array = np.append(common_interested_purpose_array, temp, axis=0)\n",
    "            \n",
    "            temp = (match_from_to_purpose==0)\n",
    "            common_uninterested_purpose_array = np.append(common_uninterested_purpose_array, temp, axis=0)\n",
    "            \n",
    "            temp = (match_from_to_purpose==1)\n",
    "            uncommon_interest_array = np.append(uncommon_interest_array, temp, axis=0)\n",
    "              \n",
    "        else:\n",
    "            common_interested_purpose_array = np.append(common_interested_purpose_array, no_user_data, axis=0)\n",
    "            common_uninterested_purpose_array = np.append(common_uninterested_purpose_array, no_user_data, axis=0)\n",
    "            uncommon_interest_array = np.append(uncommon_interest_array, no_user_data, axis=0)\n",
    "            \n",
    "    common_interest_purpose_columns = [\"common_interest_purpose_\"+str(i) for i in range(1, 16)]\n",
    "    common_interested_purpose_df = pd.DataFrame(common_interested_purpose_array, columns=common_interest_purpose_columns)\n",
    "    common_interested_purpose_df['from-to'] = from_to\n",
    "    common_interested_purpose_df['common_interest_purpose_count'] = common_interested_purpose_df[common_interest_purpose_columns].sum(axis=1)\n",
    "    common_interested_purpose_df = common_interested_purpose_df[['from-to'] + common_interest_purpose_columns+ ['common_interest_purpose_count']]\n",
    "    \n",
    "    common_uninterested_purpose_columns = [\"common_uninterested_purpose_\"+str(i) for i in range(1, 16)]\n",
    "    common_uninterested_purpose_df = pd.DataFrame(common_uninterested_purpose_array, columns=common_uninterested_purpose_columns)\n",
    "    common_uninterested_purpose_df['from-to'] = from_to\n",
    "    common_uninterested_purpose_df['common_uninterest_purpose_count'] = common_uninterested_purpose_df[common_uninterested_purpose_columns].sum(axis=1)\n",
    "    common_uninterested_purpose_df = common_uninterested_purpose_df[['from-to'] + common_uninterested_purpose_columns + ['common_uninterest_purpose_count']]\n",
    "    \n",
    "    uncommon_interested_purpose_columns = [\"uncommon_interested_purpose_\"+str(i) for i in range(1, 16)]\n",
    "    uncommon_interested_purpose_df = pd.DataFrame(uncommon_interest_array, columns=uncommon_interested_purpose_columns)\n",
    "    uncommon_interested_purpose_df['from-to'] = from_to\n",
    "    uncommon_interested_purpose_df['uncommon_interested_purpose_count'] = uncommon_interested_purpose_df[uncommon_interested_purpose_columns].sum(axis=1)\n",
    "    uncommon_interested_purpose_df = uncommon_interested_purpose_df[['from-to'] + uncommon_interested_purpose_columns + ['uncommon_interested_purpose_count']]\n",
    "    \n",
    "    \n",
    "    return common_interested_purpose_df, common_uninterested_purpose_df, uncommon_interested_purpose_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel_columns = user_purpose.columns[user_purpose.columns.str.contains('purpose')]\n",
    "\n",
    "train_common_interested_purpose_df, train_common_uninterested_purpose_df, train_uncommon_interested_purpose_df = get_common_purpose(user_df=train_prod.loc[0:10,:].copy(), \n",
    "                                                                                                                                    purpose_df=user_purpose, \n",
    "                                                                                                                                    purpose_columns=sel_columns)\n",
    "\n",
    "test_common_interested_purpose_df, test_common_uninterested_purpose_df, test_uncommon_interested_purpose_df = get_common_purpose(user_df=test_prod.loc[0:10,:].copy(), \n",
    "                                                                                                                                 purpose_df=user_purpose, \n",
    "                                                                                                                                 purpose_columns=sel_columns)\n",
    "\n",
    "train_common_interested_purpose_df.to_csv(\"../data/train_common_interested_purpose_df.csv\", index=False)\n",
    "train_common_uninterested_purpose_df.to_csv(\"../data/train_common_uninterested_purpose_df.csv\", index=False)\n",
    "train_uncommon_interested_purpose_df.to_csv(\"../data/train_uncommon_interested_purpose_df.csv\", index=False)\n",
    "\n",
    "test_common_interested_purpose_df.to_csv(\"../data/test_common_interested_purpose_df.csv\", index=False)\n",
    "test_common_uninterested_purpose_df.to_csv(\"../data/test_common_uninterested_purpose_df.csv\", index=False)\n",
    "test_uncommon_interested_purpose_df.to_csv(\"../data/test_uncommon_interested_purpose_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_common_interested_purpose_df = pd.read_csv(\"../data/train_common_interested_purpose_df.csv\")\n",
    "train_common_uninterested_purpose_df = pd.read_csv(\"../data/train_common_uninterested_purpose_df.csv\")\n",
    "train_uncommon_interested_purpose_df = pd.read_csv(\"../data/train_uncommon_interested_purpose_df.csv\")\n",
    "\n",
    "test_common_interested_purpose_df = pd.read_csv(\"../data/test_common_interested_purpose_df.csv\")\n",
    "test_common_uninterested_purpose_df = pd.read_csv(\"../data/test_common_uninterested_purpose_df.csv\")\n",
    "test_uncommon_interested_purpose_df = pd.read_csv(\"../data/test_uncommon_interested_purpose_df.csv\")\n",
    "\n",
    "print(train_prod.shape)\n",
    "train_prod = train_prod.merge(train_common_interested_purpose_df, on='from-to', how='left')\n",
    "print(train_prod.shape)\n",
    "train_prod = train_prod.merge(train_common_uninterested_purpose_df, on='from-to', how='left')\n",
    "print(train_prod.shape)\n",
    "train_prod = train_prod.merge(train_uncommon_interested_purpose_df, on='from-to', how='left')\n",
    "print(train_prod.shape)\n",
    "\n",
    "print(test_prod.shape)\n",
    "test_prod = test_prod.merge(test_common_interested_purpose_df, on='from-to', how='left')\n",
    "print(test_prod.shape)\n",
    "test_prod = test_prod.merge(test_common_uninterested_purpose_df, on='from-to', how='left')\n",
    "print(test_prod.shape)\n",
    "test_prod = test_prod.merge(test_uncommon_interested_purpose_df, on='from-to', how='left')\n",
    "print(test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_users_strength_vote_diff(strength, df):\n",
    "    \n",
    "    strength_col = strength.columns[strength.columns.str.contains('strength')]\n",
    "    \n",
    "    from_to_list = []\n",
    "    strength_diff= np.empty(shape=(0, 8))\n",
    "    for i, dataframe in tqdm(df[['from-to', 'from', 'to']].iterrows(), total=len(df)):\n",
    "        from_to = dataframe['from-to']\n",
    "        from_user = dataframe['from']\n",
    "        to_user = dataframe['to']\n",
    "        \n",
    "        from_strength = strength.loc[strength.user_id==from_user, strength_col].reset_index(drop=True)\n",
    "        to_strength = strength.loc[strength.user_id==to_user, strength_col].reset_index(drop=True)\n",
    "        \n",
    "        if (from_strength.shape[0] == 0 and to_strength.shape[0] == 0):\n",
    "            strength_diff = np.append(strength_diff, np.array([0]*8).reshape(1, -1), axis=0)\n",
    "        elif (from_strength.shape[0] == 0):\n",
    "            temp = (np.array([0]*8) - to_strength).values\n",
    "            strength_diff = np.append(strength_diff, temp.reshape(1,-1), axis=0)\n",
    "        elif (to_strength.shape[0] == 0):\n",
    "            temp = (from_strength - np.array([0]*8)).values\n",
    "            strength_diff = np.append(strength_diff, temp.reshape(1,-1), axis=0)        \n",
    "        else:                    \n",
    "            temp = (from_strength - to_strength).values\n",
    "            strength_diff = np.append(strength_diff, temp.reshape(1,-1), axis=0)\n",
    "                \n",
    "        from_to_list.append(from_to)\n",
    "    \n",
    "    cols=['common_strength_id'+str(i+1) for i in range(len(strength_col))]\n",
    "    strength_diff_df = pd.DataFrame(strength_diff, columns=cols)\n",
    "    strength_diff_df['from-to'] = from_to_list\n",
    "    \n",
    "    strength_diff_df = strength_diff_df[['from-to']+cols]\n",
    "    \n",
    "    return strength_diff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_strength_diff = common_users_strength_vote_diff(strength=user_strengths, df=train_prod)\n",
    "test_prod_strength_diff = common_users_strength_vote_diff(strength=user_strengths, df=test_prod)\n",
    "\n",
    "train_prod_strength_diff.to_csv(\"../data/train_prod_strength_diff.csv\", index=False)\n",
    "test_prod_strength_diff.to_csv(\"../data/test_prod_strength_diff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_strength_diff = pd.read_csv(\"../data/train_prod_strength_diff.csv\")\n",
    "test_prod_strength_diff = pd.read_csv(\"../data/test_prod_strength_diff.csv\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)\n",
    "train_prod = train_prod.merge(train_prod_strength_diff, on='from-to', how='left')\n",
    "test_prod = test_prod.merge(test_prod_strength_diff, on='from-to', how='left')\n",
    "\n",
    "train_prod.shape, test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting the total swipe days of the from and to user in the interaction swipe dataset\")\n",
    "\n",
    "def total_swipes_per_day_stats(df, side):\n",
    "    temp = df.groupby([side, 'year', 'month', 'day', 'swipe_status']).agg(total_swipes_per_day = ('swipe_status', 'count')).reset_index()\n",
    "    temp = temp.groupby([side, 'swipe_status']).agg(mean_swipes_per_day=('total_swipes_per_day', 'mean'),\n",
    "                                               median_swipes_per_day=('total_swipes_per_day', 'median'),\n",
    "                                               max_swipes_per_day=('total_swipes_per_day', 'max'),\n",
    "                                               min_swipes_per_day=('total_swipes_per_day', 'min')).reset_index()\n",
    "    temp = temp.pivot(index=side, columns='swipe_status', \n",
    "                      values=['mean_swipes_per_day', 'median_swipes_per_day',\n",
    "                              'max_swipes_per_day', 'min_swipes_per_day']).reset_index().fillna(0)\n",
    "    \n",
    "    temp.columns = [side, 'left_swipe_mean_swipes_per_day','right_swipe_mean_swipes_per_day',\n",
    "                    'left_swipe_median_swipes_per_day','right_swipe_median_swipes_per_day',\n",
    "                    'left_swipe_max_swipes_per_day','right_swipe_max_swipes_per_day',\n",
    "                    'left_swipe_min_swipes_per_day', 'right_swipe_min_swipes_per_day']\n",
    "    return temp\n",
    "\n",
    "from_total_swipe_days = total_swipes_per_day_stats(df=interaction_swipe.copy(), side='from')\n",
    "to_total_swipe_days = total_swipes_per_day_stats(df=interaction_swipe.copy(), side='to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_total_swipe_days.to_csv('../data/from_total_swipe_days.csv', index=False)\n",
    "to_total_swipe_days.to_csv('../data/to_total_swipe_days.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_prod = pd.read_pickle(\"../data/train_prod_v16.pickle\")\n",
    "test_prod = pd.read_pickle(\"../data/test_prod_v16.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_total_swipe_days = pd.read_csv('../data/from_total_swipe_days.csv')\n",
    "to_total_swipe_days = pd.read_csv('../data/to_total_swipe_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_prod.shape, test_prod.shape)\n",
    "train_prod = train_prod.merge(from_total_swipe_days, on='from', how='left')\n",
    "train_prod = train_prod.merge(to_total_swipe_days, on='to', how='left')\n",
    "\n",
    "test_prod = test_prod.merge(from_total_swipe_days, on='from', how='left')\n",
    "test_prod = test_prod.merge(to_total_swipe_days, on='to', how='left')\n",
    "\n",
    "\n",
    "train_prod.shape, test_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod.to_pickle(\"../data/train_prod_v17.pickle\")\n",
    "test_prod.to_pickle(\"../data/test_prod_v17.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
