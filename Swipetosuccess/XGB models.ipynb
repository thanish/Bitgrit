{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask import array as da\n",
    "from dask import dataframe as dd \n",
    "import dask\n",
    "from xgboost.dask import DaskDMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod = pd.read_pickle(\"../data/train_prod_v16.pickle\")\n",
    "test_prod = pd.read_pickle(\"../data/test_prod_v16.pickle\")\n",
    "\n",
    "print(train_prod.shape, test_prod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod['age_difference'] = train_prod['from_age']-train_prod['to_age']\n",
    "test_prod['age_difference'] = test_prod['from_age']-test_prod['to_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod['to_swipe_by_session_percentage'] = train_prod['to_total_swipe_counts']/ train_prod['to_total_session_count']\n",
    "train_prod['from_swipe_by_session_percentage'] = train_prod['from_total_swipe_counts']/ train_prod['to_total_session_count']\n",
    "\n",
    "test_prod['to_swipe_by_session_percentage'] = test_prod['to_total_swipe_counts']/ test_prod['to_total_session_count']\n",
    "test_prod['from_swipe_by_session_percentage'] = test_prod['from_total_swipe_counts']/ test_prod['to_total_session_count']\n",
    "\n",
    "train_prod['to_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['to_swipe_left_count']\n",
    "train_prod['from_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['from_swipe_left_count']\n",
    "\n",
    "train_prod['to_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['to_swipe_right_count']\n",
    "train_prod['from_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['from_swipe_right_count']\n",
    "\n",
    "train_prod['to_overall_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['to_total_swipe_counts']\n",
    "train_prod['from_overall_common_users_left_swipe_percentage'] = train_prod['common_users_swiped_left']/train_prod['from_total_swipe_counts']\n",
    "\n",
    "train_prod['to_overall_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['to_total_swipe_counts']\n",
    "train_prod['from_overall_common_users_right_swipe_percentage'] = train_prod['common_users_swiped_right']/train_prod['from_total_swipe_counts']\n",
    "\n",
    "test_prod['to_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['to_swipe_left_count']\n",
    "test_prod['from_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['from_swipe_left_count']\n",
    "\n",
    "test_prod['to_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['to_swipe_right_count']\n",
    "test_prod['from_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['from_swipe_right_count']\n",
    "\n",
    "test_prod['to_overall_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['to_total_swipe_counts']\n",
    "test_prod['from_overall_common_users_left_swipe_percentage'] = test_prod['common_users_swiped_left']/test_prod['from_total_swipe_counts']\n",
    "\n",
    "test_prod['to_overall_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['to_total_swipe_counts']\n",
    "test_prod['from_overall_common_users_right_swipe_percentage'] = test_prod['common_users_swiped_right']/test_prod['from_total_swipe_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod.fillna(-999, inplace=True)\n",
    "test_prod.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_bottom_importance = [\n",
    "                         'from_purpose_id_12',\n",
    "                         'to_unique_degree_count',\n",
    "                         'from_purpose_id_3',\n",
    "                         'from_unique_school_count',\n",
    "                         'rev_strength_4',\n",
    "                         'to_unique_school_count',\n",
    "                         'rev_strength_7',\n",
    "                         'rev_strength_8',\n",
    "                         'rev_strength_6',\n",
    "                         'rev_strength_5']\n",
    "\n",
    "self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"_self_intro_\")].tolist()\n",
    "\n",
    "to_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"to_self_intro_\")].tolist()\n",
    "from_self_intro_columns = train_prod.columns[train_prod.columns.str.contains(\"from_self_intro_\")].tolist()\n",
    "\n",
    "purpose_columns = train_prod.columns[train_prod.columns.str.contains(\"_purpose_\")].tolist()\n",
    "rev_strength_columns = train_prod.columns[train_prod.columns.str.contains(\"rev_strength\")].tolist()\n",
    "common_strength_columns = train_prod.columns[train_prod.columns.str.contains(\"common_strength\")].tolist()\n",
    "review_comments = train_prod.columns[train_prod.columns.str.contains(\"_review_comments_\")].tolist()\n",
    "\n",
    "others = ['to_review_comments_count', 'from_review_comments_count', 'to_last_login_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dep = 'score'\n",
    "drop = ['from-to', 'user_purpose_cosine_similarity', 'to_last_swipe_year']  + review_comments + rev_strength_columns + purpose_columns + to_self_intro_columns + from_self_intro_columns + common_strength_columns\n",
    "indep = train_prod.columns.difference([dep]+drop)\n",
    "\n",
    "print(\"Indep length:\",len(indep))\n",
    "print(\"Columns that are dropped:\", drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "train_local_X, test_local_X, train_local_Y, test_local_Y = train_test_split(train_prod[indep],\n",
    "                                                                            train_prod[dep], \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            stratify=train_prod[dep])\n",
    "\n",
    "print(train_local_X.shape, train_local_Y.shape, test_local_X.shape, test_local_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_eval_accuracy(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = preds.argmax(axis=1)\n",
    "    acc = accuracy_score(y_pred = preds, y_true = labels)\n",
    "    return 'Accuracy', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_prod = xgb.DMatrix(data = train_prod[indep], label = train_prod[dep])\n",
    "dtest_prod = xgb.DMatrix(data = test_prod[indep])\n",
    "dtrain_local = xgb.DMatrix(data = train_local_X, label = train_local_Y)\n",
    "dtest_local = xgb.DMatrix(data = test_local_X, label = test_local_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(dtrain_local,'train'), (dtest_local,'test')]\n",
    "\n",
    "num_rounds = 100000\n",
    "params = {'objective' : 'multi:softmax'\n",
    "          ,'num_class' : 4\n",
    "          #,'eval_metric': 'rmse'\n",
    "          ,'max_depth' : 15\n",
    "          ,'eta' : 0.1\n",
    "          ,'subsample': 1\n",
    "          ,'colsample_bytree': 1\n",
    "          ,'tree_method' : 'gpu_hist'\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(\"Started training at...\", start)\n",
    "\n",
    "# Cross validation\n",
    "np.random.seed(100)\n",
    "xgb_model_cv = xgb.cv(params,\n",
    "                      dtrain_prod,\n",
    "                      nfold = 3,\n",
    "                      num_boost_round = num_rounds,\n",
    "                      feval = xgb_eval_accuracy,\n",
    "                      maximize = True,\n",
    "                      verbose_eval = True,\n",
    "                      early_stopping_rounds = 30)\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"Started ended at...\", end)\n",
    "print(\"Total training time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB local validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(\"Started training at...\", start)\n",
    "\n",
    "np.random.seed(100)\n",
    "xgb_model_local = xgb.train(params,\n",
    "                            dtrain_local,\n",
    "                            evals = eval_set,\n",
    "                            num_boost_round = num_rounds,\n",
    "                            feval = xgb_eval_accuracy,\n",
    "                            maximize = True,\n",
    "                            verbose_eval = True,\n",
    "                            early_stopping_rounds = 50)\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"Total training time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Prod model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "print(\"Started training at...\", start)\n",
    "\n",
    "local_validation = xgb_model_local.best_iteration\n",
    "final_round = xgb_model_local.best_iteration + int(0.4*xgb_model_local.best_iteration)\n",
    "\n",
    "print(\"Local best iteration:\", local_validation)\n",
    "print(\"final round:\", final_round)\n",
    "\n",
    "np.random.seed(100)\n",
    "xgb_model_prod = xgb.train(params,\n",
    "                           dtrain_prod,\n",
    "                           evals = eval_set,\n",
    "                           num_boost_round = final_round,\n",
    "                           feval = xgb_eval_accuracy,\n",
    "                           maximize = True,\n",
    "                           verbose_eval = True)\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"Total training time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feature_imp = pd.DataFrame({'columnm_names': list(xgb_model_local.get_score().keys()),\n",
    "                                'score': list(xgb_model_local.get_score().values())\n",
    "                               }).sort_values(['score'], ascending=False)\n",
    "xgb_feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_prod_prediction = xgb_model_prod.predict(dtest_prod)\n",
    "xgb_submission = pd.DataFrame({\"from-to\": test_prod['from-to'],\n",
    "                               \"score\": xgb_prod_prediction.astype('float')})\n",
    "\n",
    "xgb_submission.to_csv(\"../submissions/xgb_sub_5.csv\", index=False)\n",
    "xgb_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB on Multi-GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 100000\n",
    "params = {'objective' : 'multi:softmax'\n",
    "          ,'num_class' : 4\n",
    "          #,'eval_metric': 'rmse'\n",
    "          ,'max_depth' : 6\n",
    "          ,'eta' : 0.1\n",
    "          ,'subsample': 1\n",
    "          ,'colsample_bytree': 1\n",
    "          ,'tree_method' : 'gpu_hist'\n",
    "          }\n",
    "\n",
    "num_rounds = 10000\n",
    "\n",
    "with LocalCUDACluster(n_workers=2, threads_per_worker=8) as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(\"forming the dask local set\")\n",
    "        train_local_X_dask = dd.from_pandas(train_local_X, npartitions=4)\n",
    "        train_local_Y_dask = dd.from_pandas(train_local_Y, npartitions=4)\n",
    "        test_local_X_dask = dd.from_pandas(test_local_X, npartitions=4)\n",
    "        test_local_Y_dask = dd.from_pandas(test_local_Y, npartitions=4)\n",
    "\n",
    "        print(\"forming the dask prod set\")\n",
    "        train_prod_X_dask = dd.from_pandas(train_prod[indep], npartitions=4)\n",
    "        train_prod_Y_dask = dd.from_pandas(train_prod[dep], npartitions=4)\n",
    "        test_prod_X_dask = dd.from_pandas(test_prod[indep], npartitions=4)\n",
    "\n",
    "        print(\"Forming the DMatrix to be accepted by XGBoost\")\n",
    "        dtrain_local = DaskDMatrix(client, data = train_local_X_dask, label = train_local_Y_dask)\n",
    "        dtest_local  = DaskDMatrix(client, data = test_local_X_dask, label = test_local_Y_dask)\n",
    "        dtrain_prod = DaskDMatrix(client, data = train_prod_X_dask, label = train_prod_Y_dask)\n",
    "        dtest_prod = DaskDMatrix(client, data = test_prod_X_dask)\n",
    "\n",
    "        eval_set = [(dtrain_local,'train'), (dtest_local,'test')]\n",
    "\n",
    "        print(\"\")\n",
    "        start_time = datetime.now() + timedelta(hours=5, minutes=30)\n",
    "        print(\"Training started... at:\", start_time)\n",
    "        \n",
    "        print(\"Training the local model\")\n",
    "        np.random.seed(100)\n",
    "        local_model = xgb.dask.train(client, \n",
    "                                     params,\n",
    "                                     dtrain_local,\n",
    "                                     evals = eval_set,\n",
    "                                     num_boost_round = num_rounds,\n",
    "                                     feval = xgb_eval_accuracy,\n",
    "                                     maximize=True,\n",
    "                                     verbose_eval = True,\n",
    "                                     early_stopping_rounds = 20\n",
    "                                    )\n",
    "        \n",
    "        end_time = datetime.now() + timedelta(hours=5, minutes=30)\n",
    "        print(\"Local Training ended at:\", end_time)\n",
    "\n",
    "        total_time = (end_time - start_time)\n",
    "        print(\"It took {} mins time to complete\".format(total_time))\n",
    "        print(\"\")\n",
    "\n",
    "        bst_local = local_model['booster']\n",
    "        history_local = local_model['history']\n",
    "\n",
    "        xgb_prod_predict = xgb.dask.predict(client, bst_local, dtest_prod)\n",
    "        xgb_prod_predict = np.array(xgb_prod_predict)\n",
    "\n",
    "        best_iteration = len(history_local['test']['Accuracy'])\n",
    "        best_score = history_local['test']['Accuracy'][-1]\n",
    "        \n",
    "        print(\"Best score {} at best iteration {}\".format(best_score, best_iteration))\n",
    "\n",
    "        ###############################################################################\n",
    "        final_iteration = best_iteration + int(0.2*best_iteration)\n",
    "        print(\"Training the prod model\")\n",
    "        print(\"Final iteration:\", final_iteration)\n",
    "\n",
    "        print(\"\")\n",
    "        start_time = datetime.now() + timedelta(hours=5, minutes=30)\n",
    "        print(\"Training started... at:\", start_time)\n",
    "        \n",
    "        np.random.seed(100)\n",
    "        prod_model = xgb.dask.train(client, \n",
    "                                     params,\n",
    "                                     dtrain_prod,\n",
    "                                     evals = eval_set,\n",
    "                                     num_boost_round = final_iteration,\n",
    "                                     feval = xgb_eval_accuracy,\n",
    "                                     maximize=True,\n",
    "                                     verbose_eval = True,\n",
    "                                     early_stopping_rounds = 20\n",
    "                                    )\n",
    "        end_time = datetime.now() + timedelta(hours=5, minutes=30)\n",
    "        print(\"Local Training ended at:\", end_time)\n",
    "\n",
    "        bst_prod = prod_model['booster']\n",
    "        history = prod_model['history']\n",
    "\n",
    "        xgb_prod_predict = xgb.dask.predict(client, bst_prod, dtest_prod)\n",
    "        xgb_prod_predict = np.array(xgb_prod_predict)\n",
    "\n",
    "        best_iteration = len(history['test']['Accuracy'])\n",
    "        best_score = history['test']['Accuracy'][-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_submission = pd.DataFrame({\"from-to\": test_prod['from-to'],\n",
    "                               \"score\": xgb_prod_predict.astype('float')})\n",
    "\n",
    "xgb_submission.to_csv(\"../submissions/xgb_sub_4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
